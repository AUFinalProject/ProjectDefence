\documentclass{article}
\usepackage[utf8]{inputenc}

\usepackage[square,numbers]{natbib}
\bibliographystyle{abbrvnat}

\usepackage{xcolor}
\pagestyle{headings}
\usepackage{hyperref}
\usepackage{array}
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
\newcolumntype{M}[1]{>{\centering\arraybackslash}m{#1}}
\usepackage{longtable}
\usepackage{romannum}
\usepackage{multirow}
\usepackage{graphicx} %package to manage images
\graphicspath{ {images/} }
% Here are our name and address.
\title{\textbf{Malware Research in PDF Files\\{\small A multidisciplinary approach in the identification of malicious PDF files.}}}
\author{Shir Bentabou \qquad Alexey Titov\\
		\\
		{\normalsize Advisors: Ph.D. Amit Dvir and Ph.D. Ran Dubin}\\
		{\small{\textit{Ariel University,Department of Computer Sciences,40700 Ariel, Israel}}}}
\date{}
%----

\begin{document}
\renewcommand{\thepage}{\arabic{page}}% Arabic page numbers
\pagecolor{yellow!20}
% title page
\begin{titlepage}
    \begin{center}
        \vspace*{1cm}
 
        \Huge
        \textbf{Malware Research in PDF Files}
 
        \vspace{0.5cm}
        \LARGE
        A multidisciplinary approach in the identification of malicious PDF files.
 
        \vspace{1.5cm}
 
        \textbf{Shir Bentabou \qquad Alexey Titov}
        \\
        Advisor: Ph.D. Amit Dvir and Ph.D. Ran Dubin
        \vfill
 
        \vspace{0.8cm}
 
        \includegraphics[width=0.4\textwidth]{university}
 
        \Large
        Department of Computer Science\\
        Ariel University\\
        Israel\\
        04.09.2019
 
    \end{center}
\end{titlepage}

% title
\maketitle
% Here is the abstract.
\begin{abstract}
		Cyber is a prefix used in a growing number of terms that describe new 
		actions that are being made possible by the usage of computers and networks.
		The main terms in those are cyber crime, cyber attack and cyber warfare, 
		all of those can be carried out by malwares.\newline
		\indent Malware, or malicious software, is any software intentionally designed to invade, 
		cause damage, or disable computers, mobile devices, server, client,or computer 
		network. Malware does the damage after it is implanted or introduced in some way 
		into a target’s computer. Nowadays there are many distribution strategies for malwares 
		and many programs  are used as platforms. Some of these programs are in the user's 
		everyday use, and seem pretty innocent. In our project we will focus on PDF 
		files as a platform for malware distribution.\newline
		\indent PDF, Portable Document Format, is used for over 20 years worldwide, and has become 
		one of the leading standards for the dissemination of textual documents. A typical user uses this format due to its flexibility and functionality,but it also attracts hackers who exploit various types of 
		vulnerabilities available in this format, causing PDF to be one of the leading vectors of malicious code 
		distribution. 
		
		
		\indent Users normally open PDF files because they have confidence in this format, and thus allow malwares to run due to vulnerabilities found in the readers.
		Therefore,  many threat analysis platforms are trying to identify the main functions that characterize the behavior of malicious PDF files by analyzing their contents, in order to learn how to automatically recognize old and new attacks.
		
		\indent The target of our work is to test and analyze how the combination of three different approaches and the use of machine learning methods can lead to effective recognition of malwares in PDF documents.
\end{abstract}
%----
\newpage

\tableofcontents

\newpage
\section{Introduction}
\indent \textbf{Cyber} is a prefix used in a growing number of terms that describe new actions that are being made possible by the usage of computers and networks. As the evolution of modern computers and networks progressed, a cat-and-mouse game evolved simultaneously, and continues to this day. This cat-and-mouse game is cyber warfare, and is caused by the challenges in information security, as a result of various cyber threats that exist.

\indent The first known cyber-attack is the Morris worm, when a student in Cornell university wanted to know how many devices existed in the internet. He wrote a program that passed between computers and this program asked each device it reached to send a signal to a control server that counted the signals sent to him. Nowadays the growth in number of cyber-attacks is unimaginable; according to published data by Check Point Software Technologies, there were 23,208,628 attacks in February 23rd, 2019 alone.

\indent The growth in cyber-attacks is not only in the numeric value, but also in the different kinds of attacks that exist. There are many different types of threats, and usually they consist of one or more kinds of attacks in the following list:

\begin{table}[htb]
\centering
\begin{tabular}[c]{|c|c|c|c|}
\hline
Advanced Persistent & \multirow{ 2}{*}{DDoS} & Intellectual Property & Rogue \\
Threats & & Theft & Software\\
\hline
\multirow{ 2}{*}{Phishing} & Wiper & \multirow{ 2}{*}{Spyware/Malware} & Unpatched \\
 & Attacks & & Software \\
\hline
Trojans & Money Theft & MITM &  \\
\hline
\multirow{ 2}{*}{Botnets} & Data & Drive-By Downloads &  \\
 & Manipulation & & \\
\hline
\multirow{ 2}{*}{Ransomware} & Data & \multirow{ 2}{*}{Malvertising} &  \\
 & Destruction & & \\ 
\hline
\end{tabular}
\caption{List including different kinds of cyber-attacks.}
\end{table}


\indent Phishing is one of the popular distribution methods for malware. It is the fraudulent attempt to obtain sensitive information from a target by disguising as a trustworthy entity in electronic communication. Phishing is typically carried out by e-mail spoofing, and often directs users to enter personal information at a fake website or by sending fake but credible documents, often PDFs.

\indent Threats as these come from various sources. The profile of the attackers does not match one certain type and depends on the source's interests and available technology. The most common sources of cyber threats are: nation states or national governments, terrorists, industrial spies, organized crime groups, hacktivists and hackers, business competitors, and disgruntled insiders.

\indent \textbf{Malware}, or malicious software, is any software designed to serve any kind of cyber-attack. Software is considered malware based on the intent of the creator rather than its actual features. Different kinds of malware serve for different uses, and it does the damage after it is implanted or introduced in some way into a target's computer. 

\indent The first recorded malware was named Elk Cloner, created by 15-year-old high school student Rich Skrenta as a prank, and affected Apple \Romannum{2} systems in 1982. This virus was disseminated by infected floppy disks and spread to all the disks that were attached to the system by attaching itself to the OS.

\indent What started as a teenage prank in 1982, has evolved into a wide range of variated software that is used today as malwares. The main types of malwares that exist today are: 

\begin{itemize}
  \item Trojan Horse – This type of malware infects a computer and usually runs in the background, sometimes for long periods of time, and gains unauthorized access to the affected computer, gathers information about the user / machine it is installed on. The information gathered by the trojan is then sent to the attacker, normally a server side that stores the data for the attacker.
  \item Virus - A virus is software usually hidden within another program that can produce copies of itself and insert them into other programs or files, and usually performs a harmful action.
  \item Worm -  Similar to viruses, worms self-replicate in order to spread to other computers over a network, usually causing harm by destroying data and files.
  \item Spyware - Malware that secretly observes the computer user's activities without permission and reports it to the software's author.
  \item Exploits - Malware that takes advantage of bugs and vulnerabilities in a system in order to allow the exploit’s creator to take control.
  \item Ransomware - Malware that locks you out of your device and/or encrypts your files, then forces you to pay a ransom to get them back.
\end{itemize}

\indent And other forms…
\newline
\newline
\indent Writing malware of the kinds we have seen above alone is not enough to create a cyber-attack. The malware must reach the target's system and operate on it in order to carry out an attack, and for that there are many distribution methods, some of them are explained below:

\begin{itemize}
  \item Social Engineering - Socially engineered attacks exploit weaknesses of humans rather than weaknesses of software. Users are manipulated into running malicious binaries believing it is safe.
  \item E-Mail – E-Mail attacks can exploit vulnerabilities in the e-mail software or in the libraries that the e-mail software uses. Moreover, viruses and trojans are often disguised as innocent e-mail attachments in phishing e-mails.
  \item Network Intrusion - Network intrusion attacks are initiated by the attacker. The attacker finds some vulnerability in the network and takes advantage of it to infect some system in the network.
  \item Links - Links typically lead to malicious sites that download malware to the victim's device when they load the page.
  \item Infected Storage Devices - Storage devices can be used as a distribution method when they are infected with malware, and when plugged into a device, they can transfer their contents to the device and infect it.
  \item Drive-by Downloads – Relates to the unintended download of malware from the internet, either without the user knowing, or with their authorization without understanding the consequences.
\end{itemize}

\indent All the above methods intend to distribute malware to systems, normally without the users being aware that the process has happened at all. In order to do that, the platforms used in these methods are well known files and programs in the user’s daily use. A very popular file type for distributing malware is PDF, Portable Document Format. In our project we will focus on PDF files as a platform for malware distribution.

\indent \textbf{PDF}, Portable Document Format, is a file format used for over 20 years worldwide, and has become one of the leading standards for the dissemination of textual documents. Based on the PostScript language, each PDF file encapsulates a complete description of a fixed-layout flat document, including the text, fonts, vector graphics, raster images and other information needed to display it. PDF files are composed by a set of sections:

\begin{figure}[htb]
\centering
\begin{tabular}[c]{|c|}
\hline
Header\\
\hline
\\
Body\\
\\
\hline
‘xref’ Table\\
\hline
Trailer\\
\hline
\end{tabular}
\caption{The structure of a PDF file.}
\end{figure}

\begin{enumerate}
	\item \textbf{PDF Header} - This is the first line of a PDF file and it specifies the version number of the used PDF specification which the document uses (e.g. ”\%PDF-1.7”).
	\item \textbf{PDF Body} - The body of the PDF document is composed of objects that typically include text streams, fonts, images, multimedia elements, etc. The body section is used to hold all the document's data that is shown to the user.
Notice that streams are interesting to us in the security aspect because they can store a large amount of data and thus store executable code that runs after some event.
    \newpage
	\item \textbf{Cross-Reference Table} – Also called 'xref' table, this table contains the references to all the objects in the document. The purpose of a cross reference table is that it allows random access to objects in the document, so we don't need to read the whole PDF document to locate an object. Each object is represented by one entry in the table, which is always 20 bytes long. If the document changes, the table is updated automatically.
	\item \textbf{Trailer} – This section specifies how the application that reads the PDF document should find the cross-reference table and other special objects in the document. The trailer section also contains the EOF indicator.
\end{enumerate}

\indent Following is a simple example of a PDF file \cite{1}. This example gives us a notion of how the PDF files look like before they are parsed. These contents can be seen for every PDF file, by opening it with any kind of text editor. In more complex files, it is possible to see different kinds of objects in the body section. Every object resides between /Obj – /Endobj tags and contains different kinds of data. For example, streams can contain large amounts of data (even executable code) and are normally compressed. Due to that they are not readable without using some tool to decompress the data.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.90\textwidth]{HWexample}
    \\
    \caption{PDF file ‘Hello World’ example\cite{1}.}
    \label{fig:HW}
\end{figure}

\indent PDF is used widely around the world since it's creation, and still is because of two main advantages that it provides compared to other file formats: (1) \textbf{PDF files are compatible across multiple platforms} - A PDF reader presents a document independently of the hardware, operating system and application software used to create the original PDF file. The PDF format was designed to create transferable documents that can be shared across multiple computer platforms. (2) \textbf{The software for viewing PDF files is free} - Most PDF Readers, including Adobe Reader, are free to the public.  This ensures that anyone you send the file to will be able to see the full version of your document.

\indent A typical user uses this format due to its flexibility and functionality, but it also attracts hackers from the same reasons: it enables cross platform attacks and is widely used (including specific targets for attacks) because many readers are free. Moreover, there are various types of vulnerabilities available in this format, causing PDF to be one of the leading vectors of malicious code distribution. The vulnerabilities available in PDF derive from PDF's support of various types of data in addition to text such as JavaScript, Flash, media files, interactive forms or links to external files and URLs. Moreover, a lot of the PDF's content (JS, URLs, etc.) may be invisible to the user opening it.

\indent In addition to that, PDF files are believed to be less suspicious than executable files. It is a common security practice for an IT administrator to define a policy to block executable files from staff e-mail attachments or web downloads, but it is rare to block PDF documents in such a manner. Users normally open PDF files because they have confidence in this format, and thus allow malwares to run due to vulnerabilities found in the readers. Therefore, many threat analysis platforms are trying to identify the main functions that characterize the identity and behavior of malicious PDF files by analyzing their contents, in order to learn how to automatically recognize old and new attacks.

\section{Related Work}
\indent In this project we will focus on phishing carried out through PDF files, that means making the user download some file believing it is safe or entering an unsecure website not knowingly. This can be done easily using PDF because PDF files allow hyperlinks to be embedded in them for easy use, and also enables the use of JavaScript and PDF object streams in the body part of the file, and this way code can be executed without the user knowing, or with his knowledge but without the awareness that this could be unsafe for him. URLs are a main method for this kind of phishing, as the user can click or hover over a hyperlink in a PDF file and be directed to a malicious website or to download a malicious file. Moreover, because of the JavaScript and streams that can be part of the PDF file, this can happen without the user knowing, in the background \cite{Bonan2018ML} \cite{JSSrndic2011Laskov}.

\indent In general, there are many tools available in the software market for the classification of files and URLs as malicious or benign. Anti-virus products normally work in a static way, producing signatures for the identification of malicious files/URLs. In addition to that, dictionaries are in use in a remote server. Signatures are kept in these dictionaries in order to identify malicious files/URLs, and are frequently updated. Most of the AVs also use blacklists, these lists contain URLs, IPs and more, and every time the AVs identify a communication with some address in the blacklists, they will block it. Apart from the static tools there are dynamic analysis tools using sandbox environments that examine the behavior of a file/URL in a separated environment \cite{patil2018malicious}. 

\indent In previous works, we have seen projects that were meant to identify malicious PDF files, and in surveys we have read \cite{BGU2014survey} \cite{Baldoni2018survey}, there have been various attempts to identify malicious files by using a range of features of the PDF file (notice that features are also tags used in the objects of the file). These features were combined to create a feature vector for the files and provided as input to machine learning algorithms (from variated kinds) that classified the files benign or malicious \cite{torres2018malicious} \cite{Bonan2018ML}. Most of these surveys based their work on Didier Stevens \cite{1}  and Otsubo's \cite{OtsuboChecker} research and tools. The objective of these researches was to create algorithms that identify malicious files with low FP (False Positive) and FN (False Negative) rates and classify files efficiently with the shortest time and resources needed.

\indent In Torres and De Los Santos research \cite{torres2018malicious}, they have combined four different PDF analysis tools, different sets of features (based on 21 features Didier Stevens chose in his research \cite{1}), and three machine learning algorithms (Support Vector Machine, Random Forest, Multilayer Perceptron) to find the most efficient way to classify if a PDF is malicious or benign, using machine learning. The achieved results are shown in the table below. In their research, MLP algorithm showed the best results.

\begin{table}[htb]
\centering
\begin{tabular}[c]{|c|c|c|c|c|}
\hline
\textbf{Algorithm} & \textbf{Accuracy} & \textbf{Recall} & \textbf{F1-Score} & \textbf{ROC-AUC}\\
\hline
\textbf{SVM} & 0.50 & 0 & 0 & 0.70\\
\hline
\textbf{RF} & 0.92 & 0.94 & 0.92 & 0.98\\
\hline
\textbf{MLP} & 0.96 & 0.967 & 0.96 & 0.98\\
\hline
\end{tabular}
\caption{Table of Torres and De Los Santos \cite{torres2018malicious} test results.}
\end{table}

\indent In another aspect of our work, we have read articles and researches about URL analysis, and how to classify if a URL is malicious or benign. From what we have read we have seen that not only static analysis tools and blacklists were used, but also a lexicographic approach was used in most of them, to improve the success rates of classifying URLs. 

\clearpage
\newpage

\indent In D. R. Patil and J. B. Patil’s research \cite{patil2018malicious}, they have provided an effective hybrid methodology to classify URLs. They have used supervised decision tree learning classification models and performed the experiments on a balanced dataset. The experimental results show that, by including new features, the decision tree learning classifiers worked well on the dataset, achieving 98\%-99\% detection accuracy with very low FP and FN rates. Moreover, using the majority voting technique, the experiments achieved 99.29\% detection accuracy with very low FP and FN rates, which is better than the existing anti-virus and anti-malware solutions for URLs.

\indent In our project we will create an ensemble machine that will focus on three different areas of a PDF file. These three areas are: 1) The image of the first page of the PDF file, 2) The text of the first page of the PDF file, and 3) The features of the PDF file. Although the third area has already been quite researched, the two first areas have not yet been researched, therefore specific researches about it haven't been found. This means we will enter a new field of research, hoping to reach some progress in finding an efficient and effective way to identify these kinds of attacks. 

\begin{figure}[h]
    \centering
    \includegraphics[width=1.00\textwidth]{machines}
    \\
    \caption{our schema for project}
    \label{fig:blur}
\end{figure}
\section[PDF Based Attack Techniques]{PDF Based Attack Techniques \cite{BGU2014malicious}}
\indent	It is known that there are many types of attacks that are based on PDF files. This is a subject that has been researched thoroughly in the past decade. Using a PDF file as an attack vector can be very simple. As mentioned above, AVs do not always have the best solution to deal with malicious PDF files, as they base their signatures on a file’s MD5 or hash, and even a small change in the file can change the MD5 or hash, and the vulnerabilities can continue to be used.

\indent There are many ways that PDF files can be used as an attack vector. Readers have many vulnerabilities that ease the use of PDF files, and many of the characteristics of the PDF file make it a great attack vector. In this section we will present the existing approaches of utilizing PDF files in order to conduct an attack \cite{BGU2014malicious}. Social engineering takes a big part of most PDF based attacks, as the user-visible content of the PDF file can exist only for social engineering causes, while the not-user-visible content of the file can be extremely malicious.

\indent \underline{JavaScript code attacks}: PDF files can contain JavaScript code for legitimate purposes, for example multimedia content and form validation. The main indicator for JavaScript code embedded in a PDF file is the presence of the ‘/JS’ tag \cite{1} \cite{JSSrndic2011Laskov} \cite{Bonan2018ML} \cite{JAST2018}. Normally, the goal of malicious JavaScript in a PDF file is to exploit a vulnerability in the PDF reader in order to execute embedded malicious JavaScript code. Downloading an executable file can also be carried out using JavaScript. Alternatively, JavaScript code can also open a malicious website that can perform a variety of malicious operations.

\indent JavaScript code obfuscation is legitimately used to prevent reverse engineering for copyright purposes. However, it can also be used by attackers to conceal malicious JavaScript code, prevent it from being recognized by signature based or lexical analysis tools \cite{JSSrndic2011Laskov}, and to reduce readability by a human security analyst. Data in the streams of a PDF can be compressed and this way hide malicious JavaScript code in them.

\indent \underline{Embedded file attack}: A PDF file can contain other file types in it, including HTML, JavaScript, executables, Microsoft Office files, and even additional PDF files. An attacker can use this functionality in order to embed a malicious file inside a benign file. This way, the attacker can utilize the vulnerabilities of other file types in order to perform malicious activity. The embedded file can be opened when the PDF file is opened using embedded JavaScript code or by other techniques such as PDF tags (such as ‘/Launch’). Usually, embedded malicious files are obfuscated in order to avoid detection. Adobe Reader PDF viewer versions 9.3.3 and above restrict file formats that can be opened, using a blacklist which is based on file extension.

\indent \underline{Form submission and URL / URI attacks}: Adobe Reader supports the option of submitting the PDF form from a client to a specific server using the '/SubmitForm’ command. Adobe then generates a file from a PDF in order to send the data to a specified URL. If the URL belongs to a remote web server, it is able to respond. An attack can be performed by a simple request to a malicious website that will automatically open on the web browser, and the malicious website can exploit a vulnerability in the user's browser. Security mechanisms such as the protected mode of Adobe Reader can be disabled easily. Moreover, a URI address can be used to refer to any file type located remotely (both executable and non-executable files).

\section{Our Work}
\indent The attacks mentioned in the previous section can be visible to the user and require some action from the user, or be completely invisible and happen in the background without the user knowing. In our project we will focus on three ways to identify malicious attacks in PDF files:

\begin{enumerate}
	\item \underline{Preview of the files} – Anti-viruses work by creating hashes (such as MD5) for malicious files found. For every malicious file they detect, they create a hash for it, and store it in their databases, so that if they encounter these files again, they will be able to block or warn about them. The problem of this approach is that if a single attribute of the file is changed, the hash also changes, and this way a file can be only briefly changed and pass the AVs detection. PDF files can be opened for initial preview, without opening the file itself. The initial preview shows the first page of the PDF file. Please note that ‘previewing’ the file is not proven to safe.\newline
	As AVs check the files by hash that can be easily changed, we want to create a detection based on the content of the file. That means, we want to be able to extract previews for the PDF file’s first page (in the form of images), and by the content of the files be able to detect malicious files. Our aim is to create an efficient image similarity engine, to detect files by their image.
	\item \underline{Text detection} – Text detection, similar to the image detection explained above can also help detect malicious files by their content. Normally, malicious PDF files contain rather innocent content in order to be credible to the user, convincing the user to open it. Therefore, we can learn about the characteristics of malicious PDF file from the text inside them, the same way as spam filters for e-mails work.
	\item \underline{PDF tags and features} – These are the structural tags and features of a PDF file that can give us a lot of information about the file. Normally they are invisible to the simple user that uses a reader in order to view the PDF files. These tags contain all the PDF's content and can give us information about the JavaScript code inside the file, links and URLs, obfuscated code, structure of the PDF file and more.
\end{enumerate}

\indent All the samples we have used in our work were received from our advisor, Ph.D. Ran Dubin, CEO \& Co Founder at SNDBOX. SNDBOX is an artificial intelligence malware research platform. The dataset contained 9,557 samples overall, and was made up of 9,158 benign samples and 419 malicious samples.

\section{Existing Tools}
\indent During our work we have found various existing tools that helped us with our research. Many of them were found while searching for specific solutions to problems we have encountered along the way. In this section we will explain about all the tools we have used.
\begin{enumerate}
	\item \underline{PDFiD} – This tool was developed by Didier Stevens \cite{1}, and was meant to help differentiating between malicious and benign PDF files. This tool is a simple string scanner written in python. It scans a PDF file for specific tags, to check if they are included in the file, and returns the expressions and the number of times they have been found in the PDF file.
	\item \underline{JAST} – This tool was developed as part of a research by Fass et al \cite{JAST2018}, in order to detect malicious JavaScript instances. This solution combines the extraction of features from the code's abstract syntax tree with a random forest classifier. It is based on a frequency analysis of specific patterns, which are either predictive of benign or malicious samples. The analysis made by this tool is entirely static, and yields a high detection accuracy of almost 99.5\%. This tool also supplies a simple classification of JS code – if there is JS code in a (text) file or not, and if there is – if it is obfuscated or not.
	\item \underline{AnalyzePDF} – This tool analyzes PDF files by looking at their characteristics in order to add some intelligence about the file's nature – if it is malicious or benign. This tool has a module that calculates the entropy in a PDF file. It calculates the overall entropy, entropy within the streams of the PDF file, and the entropy out of the PDF file's streams \cite{AnalyzePDF2014}.
	\item \underline{PeePDF} - PeePDF is a python tool, that was made to explore PDF files in order to find out if the file can be harmful or not. This tool aims to provide the researcher with all necessary components in PDF analysis. This tool can extract all the objects in a PDF that contain suspicious elements (such as JS code) and supports object streams (that are compressed) and encrypted files. This tool can easily extract all the JavaScript from a PDF file \cite{Peepdf2016}.
\end{enumerate}

\section[First phase: Preparations]{First phase: \\ Preparations}
\indent As mentioned before, the overall idea of the project was to create three machines, each one will be a classifier on its own. Each machine will classify a PDF file as malicious or benign by some kind of information about the file. The first machine will classify the file based on the image of the first page of the file. The second machine will classify the file based on the text from the first page of the file. The third machine will classify the file based on features and metadata of the file. The fourth machine, is an ensemble machine, and will classify a PDF file based on the results of all three previous machines we described.

\indent In order to create the machines, we needed to do a few preparations first. That means, prepare the code that will provide the machines the information they need from a PDF file. The machines will use this information in order to classify the files.

\indent As explained above, in this phase we extracted the information we need for our machines from PDF files. Firstly, we defined what information was needed for every machine, and then we wrote code that extracts each type of information from a PDF file.

\begin{table}[htb]
\centering
\begin{tabular}{|p{3.5cm}|p{3.5cm}|p{3.5cm}|}
\hline
\centering{\textbf{First Machine: Image Classifier}} & \centering{\textbf{Second Machine: Text Classifier}} & \centering{\textbf{Third Machine: Feature Classifier}} \tabularnewline 
\hline
\raggedright{Extract preview of PDF file} & \raggedright{Extract text from PDF file} & \raggedright{Extract telemetry} \tabularnewline
\hline
\raggedright{} & \raggedright{Extract text from image} & \raggedright{Extract URLs} \tabularnewline
\hline
\raggedright{} & \raggedright{} & \raggedright{Extract JavaScript} \tabularnewline
\hline
\end{tabular}
\end{table}

\indent In order to create a machine that classifies the PDF file by image, we have to extract an image of the PDF file. In this stage of the project we have decided to extract the preview of the first page of the file. For that, there are libraries in python that are made specifically for the processing of PDF files, and that eased our work. We have used ‘pdf2image’ to converts a PDF to a ‘PIL’ image object, and ‘PIL’ to add image processing capabilities to our code.

\indent In order to create a machine that classifies the PDF file by text, we have to extract text from a PDF file. In this stage of the project we decided to extract the text from the first page of the file. In order to do that we used ‘PDFMiner’ and ‘pyPDF2’, tools that extract information from PDF files, including text from the file. With that said, if the PDF file holds an image in the first page (or the only page), we will have to extract text from an image, and that is another case we dealt with. For that we used ‘pytesseract’, an optical character recognition (OCR) tool for python. It recognizes and reads text embedded in images. Furthermore, we used ‘cv2’ in order to return an image of a specific page in the file.

\indent In order to create a machine that classifies the PDF file by its features, we have to find a way to extract all the features we are interested in from the PDF file. For that, there are many tools that already exist and we used them to simplify our work. For the extraction of the features we are interested in we used a number of tools: ‘PDFiD’ in order to research and choose the features we want, ‘PeePDF’ in order to extract JS and information for the JS in the file and ‘pyPDF2’ in order to extract URLs from the PDF file.

\section[Second phase: Image Based Classification Machine]{Second phase: \\ Image Based Classification Machine}
\indent In this phase, we wanted to create an image-based classification machine. This machine should classify a PDF file only by the preview of the file. The idea of classifying a PDF file by image hasn't appeared in any research we have read, thus making our work a first in some sort of way.

\subsection{Creating the vector}
\indent When we started researching for the classification of a PDF file by image and saw that no research has been made about it, we looked at much simpler examples of image classification. According to an article by Adrian Rosebrock \cite{HistogramImage}, the best strategy presented to work with a picture is using a histogram, and not working with the pixels of the picture. The histogram made much more sense in our case, since relating to the picture by pixels did not give us information we could work with.

\indent Whilst working on this machine, following a tip from our advisor, we tried to find meaningful characteristics that will indicate if a PDF is malicious or not. While searching, we found a characteristic we have seen in many files, and chose to refer to the blurriness of the image. We have seen many malicious samples that contained blurred images, with a message to the user that they should download some update in order to see the document. In order to calculate the blurriness of the image, we used the Laplacian method with an existing library in python (‘cv2’). This method returns a numeric value – if that value is under 150, that means that the image is blurry. Figure \ref{fig:blur} shows an example of a blurry PDF document and a non-blurry PDF document and their numeric values calculated by the Laplacian method calculation (7.02 opposed to 4837.3).

\begin{figure}[h]
    \centering
    \includegraphics[width=1.00\textwidth]{blur}
    \\
    \caption{\textit{Left side}: Blurry PDF document, \textit{Right side}: Non-blurry PDF document}
    \label{fig:blur}
\end{figure}

\indent In this stage, we had all the information we needed to construct the vector for the images, that the machine will receive as it's input. We decided that the overall size of the image vector is 513. The 512 first indexes relate to the picture's histogram, in other words, to the colors in the image (RGB – 8*8*8 = 512). The last index of the vector holds the numeric value that is returned from the Laplacian method calculation of the blurriness of the image.

\subsection{Implementing the machine}
\indent When we reached the phase of implementing the image-based classification machine, our advisors had recommended us to use K-Means-Clustering, a popular method for cluster analysis. K-Means-Clustering partitions its observations to a numeric k clusters, each observation belongs to the cluster with the nearest mean.

\indent	We have decided to implement the machine using KNN as another example, in order to have something to compare KMC with, and in order to show that what the advisors recommended was a better solution. In more advanced phases of the project we will see that KMC is indeed the better solution.

\indent	We chose KNN because it is a simple example of a machine learning algorithm that classifies the samples to one of two groups: benign or malicious. We wanted to check if a simple ‘yes-no’ classifier will give better results than a clustering algorithm we were recommended to implement. The logic of the clustering preference is that based solely on the image, there are very few cases that a ‘yes-no’ classifier can determine whether the file is malicious or not. On the other hand, a clustering algorithm can classify a sample in the same category as other similar samples, thus being a better ‘judge’ of a sample.

\subsubsection{KNN Implementation}
\indent We will start by explaining the implementations with KNN. We divided our dataset on this machine in the following way: 80\% of the samples were used for training, and 20\% for testing. At first, we had received 253 malicious samples in our dataset. We completed the dataset by adding 253 benign samples to it, so that the dataset consisted of half malicious samples and half benign samples, containing a total of 506 samples. We ran the machine with default parameters on 1, 3, 5 and 7 neighbors as the K chosen, in order to find the best result.

\begin{table}[htb]
\centering
\begin{tabular}[c]{|c|c|}
\hline
K & Results\\
\hline
1 & 90.55\%\\
\hline
3 & 89.76\%\\
\hline
5 & \textbf{91.34\%}\\
\hline
7 & 89.76\%\\
\hline
\end{tabular}
% Or to place a caption below a table
\caption{Table of results of the different Ks chosen in the KNN implementation.}
\end{table}

\indent As can be seen above, the best result we had got was from K=5, with 91.34\% success in classifying the test samples. 	
\indent As the project advanced, we had received more malicious samples, and had a dataset that contained 838 samples, consisting of half malicious samples, and half benign samples. We ran the KNN image-based machine again on the whole dataset, and reached 87.5\% accuracy of the machine on K=5 neighbors.

\subsubsection{KMC Implementation}
\indent In order to reach best results with KMC, we wanted to check what would be the best way of defining the number of clusters the algorithm should use. We used the ‘Elbow Method’ – a method designed to help finding the appropriate number of clusters in a dataset, in such a way that adding another cluster does not give better results. We used two techniques of calculating the ideal number of clusters for our machine: ‘MinMaxScaler’ and ‘StandardScaler’, in order to verify that we are reaching the best number of clusters for our machine. The ideal number of clusters depends on the size of the dataset and the samples themselves. When we had 506 samples, the ideal number of clusters was 6, and with 838 samples, the ideal number of clusters was 19 (as seen in the Figure \ref{fig:KMC}). In the clusters we have seen malicious and benign files in the same cluster, according to the basic logic we explained of clustering the images of the files by similarity.

\begin{figure}[h]
    \centering
    \includegraphics[width=1.00\textwidth]{KMC}
    \caption{Graph of the different clusters in the KMC implementation.}
    \label{fig:KMC}
\end{figure}

\indent As seen from the results above, basing our decision on the preview of the PDF file only is obviously not enough. Even the most basic hacker can easily dodge an image-based classification. There are plenty of attacks that do not need to change anything in the PDF’s visible content. Examples can be seen in the following paper \cite{davide2019malicious}.

\section[Third phase: Text Based Classification Machine]{Third phase: \\ Text Based Classification Machine}
\indent In this phase, we wanted to create a text-based classification machine. This machine should classify a PDF file only by the text that the file contains. The idea of classifying a PDF file by the text it contains hasn't been implemented in previous researches we have read, but the overall idea of checking a file by its contents exists.

\indent The first step we made regarding this phase, as part of the first phase, was to extract the text from the first page of the PDF file. In some cases, we have noticed that there was an exaggerated amount of characters, or no characters at all, that were read from a single page of the PDF file. The reason for this was that there can be some stream that represents an image or some graphical content in the file, causing us to read the stream as a whole, and that does not give us the actual content of the file. In these cases, we have decided to deal with this by extracting the text from the image of the first page of the file. This was made as explained in the first phase.

\subsection{Creating the vector}
\indent The next step is defining the vector that this machine will receive as the input for every sample. We have seen many articles about creating a text vector, and normally this was made by using word embeddings. Word embedding is a collective name for a set of language modeling and feature learning techniques in natural language processing. In word embedding, words or phrases from the vocabulary are mapped to vectors of real numbers. We have decided to try three different word embedding techniques in our project and compare between them. 

\indent The word embedding techniques we used were ‘doc2vec’, ‘word2vec’, and ‘TF-IDF’.  ‘Word2vec’ uses dictionaries that can be given to it. After some research we have decided to use ‘GoogleNews-vectors-negative300-SLIM.bin.gz’, that uses only words – in order to meet the memory limitations we had. We fixed the size of the vector to 300.

\begin{table}[htb]
\centering
\begin{tabular}{|p{3.5cm}|p{3.5cm}|p{3.5cm}|}
\hline
\centering{Doc2Vec} & \centering{Word2Vec} & \centering{TF-IDF}\tabularnewline
\hline
\raggedright{Default vector made by library.} & \raggedright{Default vector with google vocabulary.} & \raggedright{Vector is made by counting words and default parameters.}\tabularnewline
\hline
\end{tabular}
% Or to place a caption below a table
\caption{Table explains vectors.}
\end{table}

\subsection{Implementing the machine}
\indent When implementing the text-based machine, we followed our advisor's advice to use deep learning algorithms. We chose logistic regression as the deep learning algorithm we will use. We ran logistic regression on all three word embedding techniques we chose. Specifically, in ‘doc2vec’, we used two different models: Distributed Bag of Words (DBOW) and Distributed Memory with Averaging (DMA), and the combination of both in one model. The best results we have got from ‘doc2vec’ were from the combination of both models.

\subsection{Results}
\indent In the following image we present the results of the logistic regression algorithm on all three word embedding models. The dataset was split 80\% for training and 20\% for testing.

\begin{table}[htb]
\centering
\begin{tabular}[c]{|c|c|}
\hline
\centering{\textbf{Word Embedding Model}} & \centering{\textbf{Accuracy}} \tabularnewline
\hline
\centering{Doc2Vec (DBOW + DMA)} & \centering{83.3 \%}\tabularnewline
\hline
\centering{Word2Vec} & \centering{\textbf{98.4 \%}}\tabularnewline
\hline
\centering{TF-IDF} & \centering{\textbf{98.4 \%}}\tabularnewline
\hline
\end{tabular}
% Or to place a caption below a table
\caption{Table of results of the different word embedding with LR.}
\end{table}

\indent As can be seen in the results above, ‘word2vec’ and ‘TF-IDF’ gave us the best results (and the same results). We decided to run machine learning algorithms on them in order to try reaching better results. We chose the following machine learning algorithms: Random Forest Classifier, K-Nearest-Neighbors, Support Vector Machine, Multilayer Perceptron, and Naïve-Bayes. We ran these algorithms on a dataset of 506 samples (half malicious and half benign), and the results were as follows.

\begin{table}[htb]
\centering
\begin{tabular}{|p{2.5cm}|p{2.5cm}|p{2.5cm}|p{2.5cm}|}
\hline
\centering{\textbf{Word2Vec}} & \centering{\textbf{Results}} & \centering{\textbf{TF-IDF}} & \centering{\textbf{Results}} \tabularnewline
\hline
\centering{RF Classifier} & \centering{96.8 \%} & \centering{RF Classifier} & \centering{96.8 \%}\tabularnewline
\hline
\centering{KNN} & \centering{96 \%} & \centering{KNN} & \centering{63.4 \%}\tabularnewline
\hline
\centering{SVM} & \centering{95.2 \%} & \centering{SVM} & \centering{\textbf{99.2 \%}}\tabularnewline
\hline
\centering{MLP} & \centering{97.6 \%} & \centering{MLP} & \centering{97.6 \%}\tabularnewline
\hline
\centering{NB} & \centering{88.8 \%} & \centering{NB} & \centering{96.8 \%}\tabularnewline
\hline
\end{tabular}
% Or to place a caption below a table
\caption{Table of results of the different machine learning algorithms on ‘word2vec’ and ‘TF-IDF’.}
\end{table}

\indent It is important to emphasize that ‘TF-IDF’ has recognized all the malicious samples with the machine learning algorithms – except with Naïve-Bayes. As can be seen above, except for KNN algorithm, we received the best results with ‘TF-IDF’ and therefore decided to continue with this model. We ran the machine again on 838 samples (half malicious and half benign), and compared the results. The dataset was split the same way, 80\% for training and 20\% for testing.

\begin{table}[htb]
\centering
\begin{tabular}{|p{3.0cm}|p{3.0cm}|p{3.0cm}|}
\hline
\centering{\textbf{Algorithm}} & \centering{\textbf{506 Samples}} & \centering{\textbf{838 Samples}} \tabularnewline
\hline
\centering{Logistic Regression} & \centering{98.41 \%} & \centering{\textbf{97.46 \%}}\tabularnewline
\hline
\centering{KNN} & \centering{63.49 \%} & \centering{93.03 \%}\tabularnewline
\hline
\centering{MLP} & \centering{97.61 \%} & \centering{\textbf{97.46 \%}}\tabularnewline
\hline
\centering{NB} & \centering{96.82 \%} & \centering{93.03 \%}\tabularnewline
\hline
\centering{RF Classifier} & \centering{96.82 \%} & \centering{95.56 \%}\tabularnewline
\hline
\centering{SVM} & \centering{\textbf{99.20 \%}} & \centering{96.83 \%}\tabularnewline
\hline
\end{tabular}
% Or to place a caption below a table
\caption{Table with the results of ‘TF-IDF’ with all the algorithms we tried on two datasets.}
\end{table}

\indent The best results up to this stage were from the combination of MLP or LR on ‘TF-IDF’, therefore we decided to implement the machine with LR and ‘TF-IDF’.  With that said, basing our decision on the text of the PDF file only is obviously not enough. Even the most basic hacker can easily dodge a text-based classification. There are plenty of attacks that do not need to change anything in the PDF’s visible content. Examples can be seen in the following paper \cite{davide2019malicious}. 

\section[Fourth phase: Features Based Classification Machine (JS, URL, objects and streams)]{Fourth phase: \\ Features Based Classification Machine \\(JS, URL, objects and streams)}
\indent	In the fourth phase, we created a machine that classifies PDF samples as malicious or benign, based on their features. This type of machine is the most popular amongst researches we have read, and many researches we have read \cite{1} \cite{torres2018malicious} \cite{Bonan2018ML} \cite{JSSrndic2011Laskov} \cite{Hamon2013malicious} have focused on this approach. Most researches that focused on the file's features have not described in detail the features they have used; we will give some background about the features we have chosen. The features we have chosen come from four different areas: PDF Tags, JavaScript Objects \& Streams, URLs, and Entropy.

\subsection{Creating the vector}
\indent	The vector we created held 32 values, each field of the vector contained a numeric value regarding one of the features we chose. The 32 features were made up of 12 PDF tags, 10 features that characterize the URLs in the file, 7 features that characterize the JS, objects and streams in the file, and 3 features regarding the entropy of the file.

\subsubsection{PDF Tags}
\indent	In order to extract the PDF tags we were interested in, as mentioned in the project proposal chapter, there are many existing tools that were used in many researches that were available to us. In this case we have chosen to work with the ‘PDFiD’ tool by Didier Stevens \cite{1}. This tool helps us count the number of appearances of specific tags in the PDF file. The tags we have chosen were:

\begin{enumerate}
	\item \textbf{Obj} - This tag opens an object in the PDF.
	\item \textbf{Endobj} - This tag closes an object in the PDF.
	\item \textbf{Stream} - This tag opens a stream in the PDF.
	\item \textbf{Endstream} - This tag closes a stream in the PDF.
	\item \textbf{/ObjStm} - Counts the number of object streams. An object stream is a stream object that can contain other objects, and can therefore be used to obfuscate objects (by using different filters).
	\item \textbf{/JS}, \textbf{/JavaScript} - These tags indicate that the PDF document contains JavaScript. Almost all malicious PDF documents found in the wild (by Didier Stevens) contain JavaScript (to exploit a JavaScript vulnerability and/or to execute a heap spray). JavaScript can also be found in PDFs without malicious intent.
	\item \textbf{/AA}, \textbf{/OpenAction} - These tags indicate an automatic action to be performed when the file is viewed. All malicious PDF documents with JavaScript seen in the wild (by Didier Stevens) had an automatic action to launch the JavaScript without user interaction. The combination of automatic action and JavaScript makes a PDF document very suspicious.
	\item \textbf{/RichMedia} - This tag can imply presence of flash in the file.
	\item \textbf{/Launch} - This tag counts launch actions in the file.
	\item \textbf{/AcroForm} - This tag is defined if a document contains form fields, and is true if it uses XML Forms Architecture.
\end{enumerate}

\indent The first four features were chosen specifically in order to find malformations in the PDF files format. As we have seen in previous researches, many of them have specifically linked malformations in the files to malicious intents.

\subsubsection{URLs}
\indent	In order to extract the URL features we were interested in, we wrote a simple python parser that extracted what we were looking for. Due to the specific features and the format of URLs, that was not too hard to do. The features we chose are:

\begin{enumerate}
	\item Overall number of URLs in the PDF file.
	\item Number of different URLs in the PDF file.
	\item Number of URLs with the expression "File://" .
	\item Longest length of string after the second slash in the URL.
	\item Number of URLs that contain another URL in them.
	\item Number of URLs that contain encoded characters in the hostname. 
	\newline(Example: http://www.\%63\%6c\%69\%66\%74.com)
	\item Number of URLs that contain IPs in them.
	\item Number of URLs that contain suspicious expressions (such as: download, php, target, loader, login, =, ?, \&, +).
	\item Number of URLs that contain unusual ports after the colon (':').
\end{enumerate}

\subsubsection{JavaScript, Objects \& Streams}
\indent	In order to extract the JS from the files we have used an existing tool called ‘PeePDF’. We used this tool in order to extract all the JavaScript code found in each sample and searched in the code extracted features we were interested in. The JavaScript was extracted from the objects and streams of the files. 

\indent	Another tool we used was called ‘JAST’. This tool classifies whether a string has JavaScript in it or not, and knows how to recognize obfuscated JavaScript code. This helped us extract an important feature about JavaScript in the PDF file.

\indent	The features we chose are:

\begin{enumerate}
	\item Number of objects with JavaScript in them in the PDF file.
	\item Number of lines with JavaScript code in the PDF file.
	\item Kind of JavaScript in the file: no JS, regular JS, obfuscated JS.
	\item Four features for special expressions:
	\begin{enumerate}
    	\item Number of 'eval' expressions found.
	    \item Number of backslash characters found.
		\item Number of '/u0' expressions found.
		\item Number of '/x' expressions found.
	\end{enumerate}
\end{enumerate}

\subsubsection{Entropy}
\indent	Entropy is a measurement for the lack of order or predictability of the content of the PDF files. In order to extract this feature from our samples we used an existing tool called ‘AnalyzePDF’, that calculates the entropy of the files. This feature was suggested to us by our advisors. We have decided to measure the following:

\begin{enumerate}
	\item The overall entropy of the PDF file's content.
	\item Entropy inside the PDF file's streams.
	\item Entropy outside the PDF file's streams.
\end{enumerate}

\indent	All the features we have chosen were based on decisions we have made and things we have thought were interesting and important, tips from our advisors and previous researches and articles. All the tools that are mentioned in this stage are introduced in the 'existing tools' section of this work.

\subsection{Implementing the machine}
\indent	At first, we ran a few different machine learning algorithms on our 32-sized vector to find the algorithm that will give us the best results. Similar to the second machine, we chose the following algorithms: Logistic Regression, K-Nearest-Neighbors, Multilayer Perceptron, Random Forest Classifier and Support Vector Machine. We ran the machine twice, on 506 samples and on 838 samples, both datasets were made of half malicious samples and half benign samples. We split the two datasets the same way: 80\% for training and 20\% for testing.

\subsection{Results}
\begin{table}[htb]
\centering
\begin{tabular}{|p{3.0cm}|p{3.0cm}|p{3.0cm}|}
\hline
\centering{\textbf{Algorithm}} & \centering{\textbf{506 Samples}} & \centering{\textbf{838 Samples}} \tabularnewline
\hline
\centering{Logistic Regression} & \centering{84.25 \%} & \centering{82.73 \%}\tabularnewline
\hline
\centering{KNN} & \centering{59.84 \%} & \centering{70.23 \%}\tabularnewline
\hline
\centering{MLP} & \centering{57.48 \%} & \centering{61.90 \%}\tabularnewline
\hline
\centering{RF Classifier} & \centering{\textbf{92.12 \%}} & \centering{\textbf{94.64 \%}}\tabularnewline
\hline
\centering{SVM} & \centering{48.81 \%} & \centering{57.73 \%}\tabularnewline
\hline
\end{tabular}
% Or to place a caption below a table
\caption{Table with the results of the feature-based machine.}
\end{table}

\indent Note that these results are lower than most researches we have read that based their machine on the features of the PDF file \cite{torres2018malicious}. After receiving these disappointing results, we have come up with ways to improve this machine, but have not implemented those improvements. In the 'future work' section we will list the ideas we had to improve this machine. A feature-based machine only, similar to previous machines, has also proved to be not enough against evasion attacks \cite{Bonan2018ML}.

\section[Fifth phase: Creating the ensemble classifier]{Fifth phase: \\ Creating the ensemble classifier}
\indent The aim of this final phase was to create the fourth machine, an ensemble machine that will provide us with the final classification of a PDF file. This machine will classify the file based on all three classifications made by the previous machines. 

\subsection{Creating the vector}
\label{sec:vector5phase}
\indent To implement that, we decided that there are a few combinations that are worth trying and comparing, before deciding what would be the best strategy for this machine. These strategies were regarding the vector that the ensemble machine would receive as its input. The vector of this machine could be assembled in quite a few different ways, as follows:

\renewcommand{\labelitemi}{$\textendash$}
\begin{itemize}
    \item  The vector could contain only 3 fields with the decisions of all three previous machines.
    \item The vector could contain all the vectors from previous stages (513 fields for the image, 300 fields for text, 32 fields for features = 845 fields overall).
	\item The vector could contain part of the vectors from previous stages and part of the classifications of previous stages, in different combinations.
\end{itemize}

\subsection{Implementing the machine}
\indent Furthermore, depending on the vector chosen, we had to apply some machine learning algorithm, in order for this final machine to give its final classification. In order to do that, we chose six different algorithms, and ran them on the different vectors we chose. These algorithms were: AdaBoost Classifier, AdaBoost Regressor, XGB Classifier, XGB Regressor, Random Forest Classifier, Random Forest Regressor.

\subsection{Improving Vector}
\indent While running the fourth machine, we decided to examine the feature importance of the vectors. As explained above in the previous phase, we chose 32 features for the third machine of this project, and have decided to see if all of these features were being used or if they add value to our vector and machine. When we ran the fourth machine, using all previous machines, we checked for each feature if it was used in the different algorithms of the fourth machine on our samples (838 samples, half malicious and half benign). We discovered that four of the features were not being used at all, therefore we have removed them from the feature vector of the fourth machine. The features removed were: the '/AcroForm' PDF tag, the number of '/x' expressions, the number of '/u0' expressions and the number of URLs that contain encoded characters in the hostname.

\indent	Moreover, we have made the feature importance examination for all the vectors of previous machines, and have seen the following: 

\begin{table}[htb]
\centering
\begin{tabular}{|M{1.5cm}|M{1.5cm}|M{1.5cm}|M{1.5cm}|M{1.5cm}|M{1.5cm}|M{1.5cm}|}
	\hline
	\centering{} & \centering{\textbf{AdaBoost Classifier}} & \centering{\textbf{AdaBoost Regressor}} & 		\centering{\textbf{XGB Classifier}} & \centering{\textbf{XGB Regressor}} & \centering{\textbf{RF Classifier}} & \centering{\textbf{RF Regressor}}\tabularnewline
	\hline
	\centering{\textbf{Image Histogram (1-512)}} & \centering{V} & \centering{V} & \centering{V} & 			\centering{V} & \centering{V} & \centering{V}\tabularnewline
	\hline
	\centering{\textbf{Image Blur (513)}} & \centering{V} & \centering{X} & \centering{V} & 	\centering{V} & \centering{V} & \centering{V}\tabularnewline
	\hline
	\centering{\textbf{Text (514-813)}} & \centering{31/300} & \centering{138/300} & \centering{29/300} & \centering{73/300} & \centering{300/300} & \centering{271/300}\tabularnewline
	\hline
	\centering{\textbf{Features (814-845)}} & \centering{8/32} & \centering{16/32} & \centering{7/32} & \centering{10/32} & \centering{26/32} & \centering{21/32}\tabularnewline
	\hline
\end{tabular}
% Or to place a caption below a table
\caption{Table with the usage of the features in the whole vector in the fourth machine.}
\end{table}

\indent As the table above shows, only AdaBoost regressor in the fourth machine does not use the blur of the image. Moreover, only the RF classifier and RF regressor use 90\%-100\% of the text vector. The same can be said about the feature vector.

\subsection{Initial Results}
\indent	In this stage of the project we chose all sorts of possible vectors and all six machine learning algorithms mentioned above, and ran the ensemble  machine in order to compare the results and find the best combination.  We have tried the following vectors: 

\renewcommand{\labelitemi}{$\textendash$}
\begin{itemize}
	\item Overall vector (vector that contains all previous stages vectors) with 32 features, and 28 features.
	\item Vector of machine results combining KNN and KMC for the first machine, and 32 and 28 features in the third machine.
	\item Combined vector, partly made of previous stages vectors, and partly by previous machine results.
\end{itemize}

\indent In the table below, the results of all types of vectors we tried on all six machine learning algorithms for the fourth machine are presented. The best result can be seen in the last row of the table.

\begin{table}[htb]
\centering
\begin{longtable}{|M{1.5cm}|M{1.5cm}|M{1.5cm}|M{1.5cm}|M{1.5cm}|M{1.5cm}|M{1.5cm}|}
	\hline
	\centering{} & \centering{\textbf{AdaBoost Classifier}} & \centering{\textbf{AdaBoost Regressor}} & \centering{\textbf{XGB Classifier}} & \centering{\textbf{XGB Regressor}} & \centering{\textbf{RF Classifier}} & \centering{\textbf{RF Regressor}}\tabularnewline
	\hline
	\centering{\textbf{Overall vector} \\ (32 features)} & \centering{97.62 \%} & \centering{97.02 \%} & \centering{97.02 \%} & \centering{95.24 \%} & \centering{95.38 \%} & \centering{95.24 \%}\tabularnewline
	\hline
	\centering{\textbf{Overall vector} \\ (28 features)} & \centering{97.62 \%} & \centering{97.02 \%} & \centering{97.02 \%} & \centering{95.24 \%} & \centering{96.43 \%} & \centering{95.24 \%}\tabularnewline
	\hline
	\centering{\textbf{Vector of machine results} \\ (KNN + SVM + 32 features)} & \centering{92.26 \%} & \centering{90.48 \%} & \centering{94.05 \%} & 	\centering{94.05 \%} & \centering{92.26 \%} & \centering{94.05 \%}\tabularnewline
	\hline
	\multicolumn{7}{r}{\textit{Continued on next page}} \\
\end{longtable}
\end{table}

\clearpage
\newpage

\begin{table}[htb]
\centering
\begin{longtable}{|M{1.5cm}|M{1.5cm}|M{1.5cm}|M{1.5cm}|M{1.5cm}|M{1.5cm}|M{1.5cm}|}
	\hline
	\centering{\textbf{Vector of machine results} \\ (KNN + SVM + 28 features)} & \centering{92.26 \%} & \centering{91.07 \%} & \centering{92.86 \%} & 	\centering{94.64 \%} & \centering{94.64 \%} & \centering{94.64 \%}\tabularnewline
	\hline
	\centering{\textbf{Vector of machine results} \\ (KMC + SVM + 32 features)} & \centering{92.26 \%} & \centering{93.45 \%} & \centering{93.45 \%} & 	\centering{93.45 \%} & \centering{94.05 \%} & \centering{93.45 \%}\tabularnewline
	\hline
	\centering{\textbf{Vector of machine results} \\ (KMC + SVM + 28 features)} & \centering{92.26 \%} & \centering{93.45 \%} & \centering{93.45 \%} & 	\centering{93.45 \%} & \centering{94.64 \%} & \centering{95.24 \%}\tabularnewline
	\hline
	\centering{\textbf{Combined Vector} \\ (KMC + TEXT-VECTOR + 28 features)} & \centering{98.21 \%} & \centering{97.02 \%} & \centering{97.02 \%} & \centering{95.83 \%} & \centering{95.24 \%} & \centering{96.43 \%}\tabularnewline
	\hline
	\centering{\textbf{Combined Vector} \\ (KMC + SVM + 28 features)} & \centering{95.83 \%} & \centering{97.02 \%} & \centering{97.02 \%} & \centering{97.62 \%} & \centering{97.62 \%} & \centering{97.02 \%}\tabularnewline
	\hline
	\centering{\textbf{Combined Vector} \\ (IMAGE-VECTOR + SVM + 28 features)} & \centering{\textbf{98.81 \%}} & \centering{97.62 \%} & \centering{\textbf{98.81 \%}} & \centering{98.21 \%} & \centering{98.21 \%} & \centering{98.21 \%}\tabularnewline
	\hline 
\end{longtable}
% Or to place a caption below a table
\caption{Table with the results of the fourth machine on combinations of vectors and algorithms.}
\end{table}

\clearpage
\newpage

\subsection{Feature Importance}
\indent	In order to understand the relevance of each machine in the project, we ran the fourth machine on the vector of machine results and retrieved the feature importance of every algorithm. We ran the machine with the next definitions:  KMC for the first machine (image), SVM for the second machine (text) and RF for the third machine (PDF features). The results are shown in the table below:

\begin{table}[htb]
\centering
\begin{tabular}{|M{2.5cm}|M{2.5cm}|M{2.5cm}|M{2.5cm}|}
	\hline
	\centering{} & \centering{\textbf{Image}} & \centering{\textbf{Text}} & \centering{\textbf{Features}}\tabularnewline
	\hline
	\centering{\textbf{AdaBoost Classifier}} & \centering{0.93} & \centering{0.04} & \centering{0.03}\tabularnewline
	\hline
	\centering{\textbf{AdaBoost Regressor}} & \centering{0.18419997} & \centering{0.60848697} & \centering{0.20731306}\tabularnewline
	\hline
	\centering{\textbf{XGB Classifier}} & \centering{0.01018084} & \centering{0.92208797} & \centering{0.067731306}\tabularnewline
	\hline
	\centering{\textbf{XGB Regressor}} & \centering{0.01556311} & \centering{0.94997084} & \centering{0.03446609}\tabularnewline
	\hline
	\centering{\textbf{Random Forest Classifier}} & \centering{0.14533861} & \centering{0.53994799} & \centering{0.31471341}\tabularnewline
	\hline
	\centering{\textbf{Random Forest Regressor}} & \centering{0.06494484} & \centering{0.90513809} & \centering{0.02991707}\tabularnewline
	\hline
\end{tabular}
% Or to place a caption below a table
\caption{Table with the feature importance of all algorithms in fourth machine on vector of machine results.
 (First machine – KMC, second machine – SVM, third machine – RF).}
 \label{tab:First}
\end{table}

\indent From the results in the above table \ref{tab:First}, it can be seen clearly that the text feature in the vector of machine results is the most significant one in feature importance in most cases. That result awed us, as it was not expected. The text and image machines are expected to be less significant since they judge the visible content of the PDF file only. As mentioned in the first and second phase chapters, visible content in the PDF does not necessarily mean that there is not more content in the file, such as JS code and all that was mentioned in phase four.

\indent In order to improve our results in the fourth machine, we needed to go back and rethink our strategy for all three previous machines. At first, when we built the first three machines, we ran them on a dataset of 506 samples. When we ran the machines again on 838 samples – we saw different results (shown in the first, second and third phase chapters). For example, with 506 samples we saw that for the first machine (image), the best result we received was using KNN, but with 838 samples we got the best results using KMC. Moreover, with 506 samples we saw that for the second machine (text), the best result we received was using SVM, but with 838 samples we got the best results using LR.

\indent In addition to that, during our project we had a meeting with another researcher that focuses on evasion attacks. From his point of view, the first and second machines of our project were very ineffective against an attacker that is acquainted with the machines (that knows that the first page is always taken for image and text extraction). Therefore, we have added to the functionality of these machines, the option of choosing a random page of the file to extract the image and text from. The random selection for the page is done twice, once for the text, and once for the image, meaning that there may be two different pages chosen from the file (unless the length of the file is one page only). 

\section{Results}
\indent In this chapter we will present our results and explain them. We will present the final results of the ensemble machine. The vector chosen from all the options present in section \hyperref[sec:vector5phase]{10.1} was the vector of machine results, with 3 features, each representing a result from a machine (image, text, PDF features). The chosen algorithms for the first three machines are: KMC for the image classification machine, LR for the text classification machine, and RF for the PDF features classification machine.

\begin{table}[htb]
\centering
\begin{tabular}{|M{3.0cm}|M{3.0cm}|M{3.0cm}|}
	\hline
	\centering{\textbf{Result of image machine}} & \centering{\textbf{Result of text machine}} & \centering{\textbf{Result of PDF features machine}}\tabularnewline
	\hline
\end{tabular}
% Or to place a caption below a table
\caption{Vector of machine results.}
\end{table}

\indent The results are on the following two datasets in two variations for each, depending on the way the text and image pages are selected:

\begin{table}[htb]
\centering
\begin{tabular}{|M{2.5cm}|M{2.5cm}|M{2.5cm}|M{2.5cm}|}
	\hline
	\centering{\textbf{Dataset Index}} & \centering{\textbf{Number of samples}} & \centering{\textbf{Dataset content}} & \centering{\textbf{Page Selection}}\tabularnewline
	\hline
	\centering{\textbf{1}} & \centering{838} & \centering{50\% malicious, 50\% benign} & \centering{First page}\tabularnewline
	\hline
	\centering{\textbf{2}} & \centering{838} & \centering{50\% malicious, 50\% benign} & \centering{Random}\tabularnewline
	\hline
	\centering{\textbf{3}} & \centering{9,577} & \centering{95.625\% benign, 4.375\% malicious} & \centering{First page}\tabularnewline
	\hline
	\centering{\textbf{4}} & \centering{9,577} & \centering{95.625\% benign, 4.375\% malicious} & \centering{Random}\tabularnewline
	\hline
\end{tabular}
% Or to place a caption below a table
\caption{Table with the groups that we refer to in the final results.}
\end{table}

\indent For all four groups presented above, the two datasets were divided in the following way:
\renewcommand{\labelitemi}{$\textendash$}
\begin{itemize}
    \item Train first three machines: 70\% of the samples (benign and malicious respectively).
    \item Train ensemble machine: 20\% of the samples (benign and malicious respectively).
	\item Test: 10\% of the samples (benign and malicious respectively).
\end{itemize}

\subsection{Results of first group (838 samples; 50\% malicious / 50\% benign; first page for text \& image):}
\indent Firstly, we present the accuracy parameters of all six algorithms on the dataset. As can be seen in the table below, here we have received the best results from the XGB classifier, with 96.43\% accuracy. An interesting thing that can be seen in the table is that XGB regressor had more than one percent less accuracy than XGB classifier, but the precision on the benign files and the recall on the malicious files was 100\%.

\noindent\underline{Accuracy Parameters:}

\begin{table}[htb]
\centering
\begin{tabular}{|M{1.2in}|M{0.6in}|M{0.5in}|M{0.6in}|M{0.4in}|M{0.4in}|}\hline
  & \centering{\textbf{Accuracy}} & \centering{\textbf{Class}} & 		\centering{\textbf{Precision}} & \centering{\textbf{Recall}} & \centering{\textbf{F1-Score}}\tabularnewline \cline{1-6}
  \multirow{2}{1.2in}{\textbf{AdaBoost Classifier}}
  &\multirow{2}{*}{\centering{95.24\%}} & \multirow{1}{*}{\centering{Benign}} & \centering{98\%} & \centering{93\%} & \centering{95\%}\tabularnewline \cline{3-6}
  && \multirow{1}{*}{\centering{Malicious}} & \centering{93\%} & \centering{98\%} & \centering{95\%}\tabularnewline \cline{1-6}
  \multirow{2}{1.2in}{\textbf{AdaBoost Regressor}}
  &\multirow{2}{*}{\centering{92.86\%}} & \multirow{1}{*}{\centering{Benign}} & \centering{95\%} & \centering{91\%} & \centering{93\%}\tabularnewline \cline{3-6}
  && \multirow{1}{*}{\centering{Malicious}} & \centering{91\%} & \centering{95\%} & \centering{93\%}\tabularnewline \cline{1-6}
  \multirow{2}{1.2in}{\textbf{XGB Classifier}}
  &\multirow{2}{*}{\centering{\textbf{96.43\%}}} & \multirow{1}{*}{\centering{Benign}} & \centering{95\%} & \centering{98\%} & \centering{97\%}\tabularnewline \cline{3-6}
  && \multirow{1}{*}{\centering{Malicious}} & \centering{97\%} & \centering{95\%} & \centering{96\%}\tabularnewline \cline{1-6}
  \multirow{2}{1.2in}{\textbf{XGB Regressor}}
  &\multirow{2}{*}{\centering{95.24\%}} & \multirow{1}{*}{\centering{Benign}} & \centering{100\%} & \centering{91\%} & \centering{95\%}\tabularnewline \cline{3-6}
  && \multirow{1}{*}{\centering{Malicious}} & \centering{91\%} & \centering{100\%} & \centering{95\%}\tabularnewline \cline{1-6}
  \multirow{2}{1.2in}{\textbf{Random Forest Classifier}}
  &\multirow{2}{*}{\centering{94.05\%}} & \multirow{1}{*}{\centering{Benign}} & \centering{95\%} & \centering{93\%} & \centering{94\%}\tabularnewline \cline{3-6}
  && \multirow{1}{*}{\centering{Malicious}} & \centering{93\%} & \centering{95\%} & \centering{94\%}\tabularnewline \cline{1-6}
  \multirow{2}{1.2in}{\textbf{Random Forest Regressor}}
  &\multirow{2}{*}{\centering{94.05\%}} & \multirow{1}{*}{\centering{Benign}} & \centering{95\%} & \centering{93\%} & \centering{94\%}\tabularnewline \cline{3-6}
  && \multirow{1}{*}{\centering{Malicious}} & \centering{93\%} & \centering{95\%} & \centering{94\%}\tabularnewline \cline{1-6}
\end{tabular}
% Or to place a caption below a table
\caption{Accuracy parameters for all algorithms on first group.}
\end{table}

\clearpage
\newpage

\indent As in the previous chapter, we wanted to examine the feature importance of our vector, made of all three previous machines results for this group:

\noindent\underline{Feature Importance:}

\begin{table}[htb]
\centering
\begin{tabular}{|M{2.5cm}|M{2.5cm}|M{2.5cm}|M{2.5cm}|}
	\hline
	\centering{} & \centering{\textbf{Image}} & \centering{\textbf{Text}} & \centering{\textbf{Features}}\tabularnewline
	\hline
	\centering{\textbf{AdaBoost Classifier}} & \centering{0.95} & \centering{0.03} & \centering{0.02}\tabularnewline
	\hline
	\centering{\textbf{AdaBoost Regressor}} & \centering{0.23878133} & \centering{0.28937013} & \centering{0.47184864}\tabularnewline
	\hline
	\centering{\textbf{XGB Classifier}} & \centering{0.02476732} & \centering{0.87546283} & \centering{0.099769983}\tabularnewline
	\hline
	\centering{\textbf{XGB Regressor}} & \centering{0.02019422} & \centering{0.91034234} & \centering{0.06946351}\tabularnewline
	\hline
	\centering{\textbf{Random Forest Classifier}} & \centering{0.1556851} & \centering{0.46782244} & \centering{0.037649246}\tabularnewline
	\hline
	\centering{\textbf{Random Forest Regressor}} & \centering{0.10489435} & \centering{0.58775198} & \centering{0.30735367}\tabularnewline
	\hline
\end{tabular}
% Or to place a caption below a table
\caption{Feature importance for all algorithms on first group.}
\end{table}

\indent As can be seen above, the results of the feature importance change significantly between the algorithms. The result of the text importance is still relatively high in as to what we expect it to be in most algorithms.

\indent \underline{Confusion Matrices}: (Positive = Benign, Negative = Malicious) 
\indent In the following table we present the confusion matrices for all algorithms, on the first group. The columns of the table are as follows:

\renewcommand{\labelitemi}{$\textendash$}
\begin{itemize}
    \item Pos. as Pos. – Benign samples classified as benign.
    \item Pos. as Neg. - Benign samples classified as malicious.
	\item Neg. as Pos. - Malicious samples classified as benign.
	\item Neg. as Neg. - Malicious samples classified as malicious.
\end{itemize}

\clearpage
\newpage

\begin{table}[htb]
\centering
\begin{tabular}{|M{2.0cm}|M{2.0cm}|M{2.0cm}|M{2.0cm}|M{2.0cm}|}
	\hline
	\centering{} & \centering{\textbf{Pos. as Pos.}} & \centering{\textbf{Neg. as Pos.}} & \centering{\textbf{Pos. as Neg.}} & \centering{\textbf{Neg. as Neg.}}\tabularnewline
	\hline
	\centering{\textbf{AdaBoost Classifier}} & \centering{40} & \centering{1} & \centering{3} & \centering{40}\tabularnewline
	\hline
	\centering{\textbf{AdaBoost Regressor}} & \centering{39} & \centering{3} & \centering{4} & \centering{39}\tabularnewline
	\hline
	\centering{\textbf{XGB Classifier}} & \centering{42} & \centering{2} & \centering{1} & \centering{39}\tabularnewline
	\hline
	\centering{\textbf{XGB Regressor}} & \centering{39} & \centering{\textbf{0}} & \centering{4} & \centering{41}\tabularnewline
	\hline
	\centering{\textbf{Random Forest Classifier}} & \centering{40} & \centering{2} & \centering{3} & \centering{39}\tabularnewline
	\hline
	\centering{\textbf{Random Forest Regressor}} & \centering{40} & \centering{2} & \centering{3} & \centering{39}\tabularnewline
	\hline
\end{tabular}
% Or to place a caption below a table
\caption{Confusion matrices for all algorithms on first group.
Note that 84 samples are shown in the table (10\% of samples that were used for test).}
\end{table}

\indent An interesting fact from the confusion matrices is that the XGB regressor has not classified even a single malicious file as benign. 

\indent In addition to the results above, we decided to run the trained machines on the first group (machines that were trained and tested on 838 samples with the first page selected for the extraction of image and text of the PDF file) on a dataset that contained only benign samples. This all-benign dataset contained 8,739 samples that none of them were used in the previous dataset of 838 samples. The results of running the trained machines on the all-benign dataset were as follows:

\clearpage
\newpage

\begin{table}[htb]
\centering
\begin{tabular}{|M{4.0cm}|M{2.0cm}|M{2.0cm}|M{2.0cm}|}
	\hline
	\centering{} & \centering{\textbf{Accuracy}} & \centering{\textbf{Pos. as Pos.}} & \centering{\textbf{Pos. as Neg.}}\tabularnewline
	\hline
	\centering{\textbf{AdaBoost Classifier}} & \centering{95.23\%} & \centering{8322} & \centering{417} \tabularnewline
	\hline
	\centering{\textbf{AdaBoost Regressor}} & \centering{93.80\%} & \centering{8197} & \centering{542}\tabularnewline
	\hline
	\centering{\textbf{XGB Classifier}} & \centering{97.12\%} & \centering{8487} & \centering{252}\tabularnewline
	\hline
	\centering{\textbf{XGB Regressor}} & \centering{95.38\%} & \centering{8335} & \centering{404}\tabularnewline
	\hline
	\centering{\textbf{Random Forest Classifier}} & \centering{95.28\%} & \centering{8414} & \centering{325}\tabularnewline
	\hline
	\centering{\textbf{Random Forest Regressor}} & \centering{95.28\%} & \centering{8414} & \centering{325}\tabularnewline
	\hline
\end{tabular}
% Or to place a caption below a table
\caption{Result over remaining benign samples, first group}
\end{table}

\subsection{Results of second group (838 samples; 50\% malicious / 50\% benign; random pages for text \& image):}
\indent We present here the results of the second group. The difference between this group and the previous one is the way the choice of the page for the image and text is made. Here the choice for these is made randomly.

\noindent\underline{Accuracy Parameters:}

\indent	In the accuracy parameters of this group we can see that the random choice of page affected the results in all algorithms, causing a decrease in the accuracy.

\begin{table}[htb]
\centering
\begin{tabular}{|M{1.2in}|M{0.6in}|M{0.5in}|M{0.6in}|M{0.4in}|M{0.4in}|}\hline
  & \centering{\textbf{Accuracy}} & \centering{\textbf{Class}} & 		\centering{\textbf{Precision}} & \centering{\textbf{Recall}} & \centering{\textbf{F1-Score}}\tabularnewline \cline{1-6}
  \multirow{2}{1.2in}{\textbf{AdaBoost Classifier}}
  &\multirow{2}{*}{\centering{90.48\%}} & \multirow{1}{*}{\centering{Benign}} & \centering{95\%} & \centering{86\%} & \centering{90\%}\tabularnewline \cline{3-6}
  && \multirow{1}{*}{\centering{Malicious}} & \centering{87\%} & \centering{95\%} & \centering{91\%}\tabularnewline \cline{1-6}
  \multirow{2}{1.2in}{\textbf{AdaBoost Regressor}}
  &\multirow{2}{*}{\centering{91.67\%}} & \multirow{1}{*}{\centering{Benign}} & \centering{93\%} & \centering{91\%} & \centering{92\%}\tabularnewline \cline{3-6}
  && \multirow{1}{*}{\centering{Malicious}} & \centering{90\%} & \centering{93\%} & \centering{92\%}\tabularnewline \cline{1-6}
  \multirow{2}{1.2in}{\textbf{XGB Classifier}}
  &\multirow{2}{*}{\centering{91.67\%}} & \multirow{1}{*}{\centering{Benign}} & \centering{93\%} & \centering{91\%} & \centering{92\%}\tabularnewline \cline{3-6}
  && \multirow{1}{*}{\centering{Malicious}} & \centering{90\%} & \centering{93\%} & \centering{92\%}\tabularnewline \cline{1-6}
  \multirow{2}{1.2in}{\textbf{XGB Regressor}}
  &\multirow{2}{*}{\centering{92.86\%}} & \multirow{1}{*}{\centering{Benign}} & \centering{93\%} & \centering{93\%} & \centering{93\%}\tabularnewline \cline{3-6}
  && \multirow{1}{*}{\centering{Malicious}} & \centering{93\%} & \centering{93\%} & \centering{93\%}\tabularnewline \cline{1-6}
  \multirow{2}{1.2in}{\textbf{Random Forest Classifier}}
  &\multirow{2}{*}{\centering{92.86\%}} & \multirow{1}{*}{\centering{Benign}} & \centering{95\%} & \centering{91\%} & \centering{93\%}\tabularnewline \cline{3-6}
  && \multirow{1}{*}{\centering{Malicious}} & \centering{91\%} & \centering{95\%} & \centering{93\%}\tabularnewline \cline{1-6}
  \multirow{2}{1.2in}{\textbf{Random Forest Regressor}}
  &\multirow{2}{*}{\centering{92.86\%}} & \multirow{1}{*}{\centering{Benign}} & \centering{95\%} & \centering{91\%} & \centering{93\%}\tabularnewline \cline{3-6}
  && \multirow{1}{*}{\centering{Malicious}} & \centering{91\%} & \centering{95\%} & \centering{93\%}\tabularnewline \cline{1-6}
\end{tabular}
% Or to place a caption below a table
\caption{Accuracy parameters for all algorithms on second group.}
\end{table}

\clearpage
\newpage

\noindent\underline{Feature Importance:}

\indent	The feature importance was also affected from the random choice of pages for text and image extraction. The table below shows a significant decrease in the importance of the text feature, and a significant increase in the third feature, that contains the classification of the third machine on PDF features. 

\begin{table}[htb]
\centering
\begin{tabular}{|M{2.5cm}|M{2.5cm}|M{2.5cm}|M{2.5cm}|}
	\hline
	\centering{} & \centering{\textbf{Image}} & \centering{\textbf{Text}} & \centering{\textbf{Features}}\tabularnewline
	\hline
	\centering{\textbf{AdaBoost Classifier}} & \centering{0.95} & \centering{0.02} & \centering{0.03}\tabularnewline
	\hline
	\centering{\textbf{AdaBoost Regressor}} & \centering{0.44241618} & \centering{0.08196731} & \centering{0.475616652}\tabularnewline
	\hline
	\centering{\textbf{XGB Classifier}} & \centering{0.01986038} & \centering{0.04689374} & \centering{0.9332459}\tabularnewline
	\hline
	\centering{\textbf{XGB Regressor}} & \centering{0.02112981} & \centering{0.03368637} & \centering{0.9451838}\tabularnewline
	\hline
	\centering{\textbf{Random Forest Classifier}} & \centering{0.30664552} & \centering{0.22409619} & \centering{0.46925829}\tabularnewline
	\hline
	\centering{\textbf{Random Forest Regressor}} & \centering{0.11688741} & \centering{0.05400321} & \centering{0.82910937}\tabularnewline
	\hline	
\end{tabular}
% Or to place a caption below a table
\caption{Feature importance for all algorithms on second group.}
\end{table}

\noindent\underline{Confusion Matrices}: (Positive = Benign, Negative = Malicious) 

\indent Here we present the confusion matrices for all algorithms on the second group. Note that the columns of the table are the same as in presented in the previous group's results. We can see a slight decrease in the classification of the samples.

\clearpage
\newpage

\begin{table}[htb]
\centering
\begin{tabular}{|M{2.0cm}|M{2.0cm}|M{2.0cm}|M{2.0cm}|M{2.0cm}|}
	\hline
	\centering{} & \centering{\textbf{Pos. as Pos.}} & \centering{\textbf{Neg. as Pos.}} & \centering{\textbf{Pos. as Neg.}} & \centering{\textbf{Neg. as Neg.}}\tabularnewline
	\hline
	\centering{\textbf{AdaBoost Classifier}} & \centering{37} & \centering{2} & \centering{6} & \centering{39}\tabularnewline
	\hline
	\centering{\textbf{AdaBoost Regressor}} & \centering{39} & \centering{3} & \centering{4} & \centering{38}\tabularnewline
	\hline
	\centering{\textbf{XGB Classifier}} & \centering{39} & \centering{3} & \centering{4} & \centering{38}\tabularnewline
	\hline
	\centering{\textbf{XGB Regressor}} & \centering{40} & \centering{3} & \centering{3} & \centering{38}\tabularnewline
	\hline
	\centering{\textbf{Random Forest Classifier}} & \centering{39} & \centering{2} & \centering{4} & \centering{39}\tabularnewline
	\hline
	\centering{\textbf{Random Forest Regressor}} & \centering{39} & \centering{2} & \centering{4} & \centering{39}\tabularnewline
	\hline
\end{tabular}
% Or to place a caption below a table
\caption{Confusion matrices for all algorithms on second group.
Note that 84 samples are shown in the table (10\% of samples that were used for test).}
\end{table}

\indent As on the first group, here too we ran the machines that were trained on the second group (machines that were trained and tested on 838 samples with random page selection for image and text extraction) on the all-benign dataset. The results of running the trained machines on the second group on the all-benign dataset were as follows:

\begin{table}[htb]
\centering
\begin{tabular}{|M{4.0cm}|M{2.0cm}|M{2.0cm}|M{2.0cm}|}
	\hline
	\centering{} & \centering{\textbf{Accuracy}} & \centering{\textbf{Pos. as Pos.}} & \centering{\textbf{Pos. as Neg.}}\tabularnewline
	\hline
	\centering{\textbf{AdaBoost Classifier}} & \centering{93.50\%} & \centering{8171} & \centering{568} \tabularnewline
	\hline
	\centering{\textbf{AdaBoost Regressor}} & \centering{96.28\%} & \centering{8414} & \centering{325}\tabularnewline
	\hline
	\centering{\textbf{XGB Classifier}} & \centering{93.60\%} & \centering{8180} & \centering{559}\tabularnewline
	\hline
	\centering{\textbf{XGB Regressor}} & \centering{94.01\%} & \centering{8216} & \centering{523}\tabularnewline
	\hline
	\centering{\textbf{Random Forest Classifier}} & \centering{90.03\%} & \centering{7868} & \centering{871}\tabularnewline
	\hline
	\centering{\textbf{Random Forest Regressor}} & \centering{94.01\%} & \centering{8216} & \centering{523}\tabularnewline
	\hline
\end{tabular}
% Or to place a caption below a table
\caption{Result over remaining benign samples, second group.}
\end{table}

\subsection{Results of third group (9,577 samples; 95.625\% malicious / 4.375\% benign; first page for text \& image):}
\indent	In this group, as written above, we reach the larger dataset, with mostly benign samples. This dataset contains all the samples we have, and the difference in the amounts of malicious and benign samples affects the results.

\noindent\underline{Accuracy Parameters:}

\indent	In the accuracy parameters of this group we note that the AdaBoost classifier has returned the best result, 0.21\% higher than all the other algorithms that returned the same result in the accuracy parameter. 

\begin{table}[htb]
\centering
\begin{tabular}{|M{1.2in}|M{0.6in}|M{0.5in}|M{0.6in}|M{0.4in}|M{0.4in}|}\hline
  & \centering{\textbf{Accuracy}} & \centering{\textbf{Class}} & 		\centering{\textbf{Precision}} & \centering{\textbf{Recall}} & \centering{\textbf{F1-Score}}\tabularnewline \cline{1-6}
  \multirow{2}{1.2in}{\textbf{AdaBoost Classifier}}
  &\multirow{2}{*}{\centering{\textbf{99.05\%}}} & \multirow{1}{*}{\centering{Benign}} & \centering{99\%} & \centering{100\%} & \centering{100\%}\tabularnewline \cline{3-6}
  && \multirow{1}{*}{\centering{Malicious}} & \centering{92\%} & \centering{86\%} & \centering{89\%}\tabularnewline \cline{1-6}
  \multirow{2}{1.2in}{\textbf{AdaBoost Regressor}}
  &\multirow{2}{*}{\centering{98.84\%}} & \multirow{1}{*}{\centering{Benign}} & \centering{99\%} & \centering{99\%} & \centering{99\%}\tabularnewline \cline{3-6}
  && \multirow{1}{*}{\centering{Malicious}} & \centering{88\%} & \centering{86\%} & \centering{87\%}\tabularnewline \cline{1-6}
  \multirow{2}{1.2in}{\textbf{XGB Classifier}}
  &\multirow{2}{*}{\centering{98.84\%}} & \multirow{1}{*}{\centering{Benign}} & \centering{99\%} & \centering{99\%} & \centering{99\%}\tabularnewline \cline{3-6}
  && \multirow{1}{*}{\centering{Malicious}} & \centering{88\%} & \centering{86\%} & \centering{87\%}\tabularnewline \cline{1-6}
  \multirow{2}{1.2in}{\textbf{XGB Regressor}}
  &\multirow{2}{*}{\centering{98.84\%}} & \multirow{1}{*}{\centering{Benign}} & \centering{99\%} & \centering{99\%} & \centering{99\%}\tabularnewline \cline{3-6}
  && \multirow{1}{*}{\centering{Malicious}} & \centering{88\%} & \centering{86\%} & \centering{87\%}\tabularnewline \cline{1-6}
  \multirow{2}{1.2in}{\textbf{Random Forest Classifier}}
  &\multirow{2}{*}{\centering{98.84\%}} & \multirow{1}{*}{\centering{Benign}} & \centering{99\%} & \centering{99\%} & \centering{99\%}\tabularnewline \cline{3-6}
  && \multirow{1}{*}{\centering{Malicious}} & \centering{88\%} & \centering{86\%} & \centering{87\%}\tabularnewline \cline{1-6}
  \multirow{2}{1.2in}{\textbf{Random Forest Regressor}}
  &\multirow{2}{*}{\centering{98.84\%}} & \multirow{1}{*}{\centering{Benign}} & \centering{99\%} & \centering{99\%} & \centering{99\%}\tabularnewline \cline{3-6}
  && \multirow{1}{*}{\centering{Malicious}} & \centering{88\%} & \centering{86\%} & \centering{87\%}\tabularnewline \cline{1-6}
\end{tabular}
% Or to place a caption below a table
\caption{Accuracy parameters for all algorithms on third group.}
\end{table}

\noindent\underline{Feature Importance:}

\indent	The feature importance has also changed from previous groups on the smaller dataset. Here we can see a real mix-and-match in the feature importance in the algorithms. All algorithms except our leading algorithm in accuracy, AdaBoost classifier, have given very little importance to the image, and AdaBoost classifier has given almost all the importance to the image feature. This fact is a bit confusing.

\clearpage
\newpage

\begin{table}[htb]
\centering
\begin{tabular}{|M{2.5cm}|M{2.5cm}|M{2.5cm}|M{2.5cm}|}
	\hline
	\centering{} & \centering{\textbf{Image}} & \centering{\textbf{Text}} & \centering{\textbf{Features}}\tabularnewline
	\hline
	\centering{\textbf{AdaBoost Classifier}} & \centering{0.95} & \centering{0.03} & \centering{0.02}\tabularnewline
	\hline
	\centering{\textbf{AdaBoost Regressor}} & \centering{0.19335592} & \centering{0.68552074} & \centering{0.12112334}\tabularnewline
	\hline
	\centering{\textbf{XGB Classifier}} & \centering{0.01837745} & \centering{0.29502392} & \centering{0.6865986}\tabularnewline
	\hline
	\centering{\textbf{XGB Regressor}} & \centering{0.00695719} & \centering{0.44185147} & \centering{0.5511914}\tabularnewline
	\hline
	\centering{\textbf{Random Forest Classifier}} & \centering{0.03115066} & \centering{0.4734846} & \centering{0.49536474}\tabularnewline
	\hline
	\centering{\textbf{Random Forest Regressor}} & \centering{0.01641713} & \centering{0.35635909} & \centering{0.62722378}\tabularnewline
	\hline	
\end{tabular}
% Or to place a caption below a table
\caption{Feature importance for all algorithms on third group.}
\end{table}

\noindent\underline{Confusion Matrices}: (Positive = Benign, Negative = Malicious)

\indent Here we present the confusion matrices for all algorithms on the third group. These results resemble the results of the accuracy parameters in the fact that all the amounts are the same for all algorithms, except for AdaBoost classifier. The difference in the accuracy parameters can be explained by the table below.

\clearpage
\newpage

\begin{table}[htb]
\centering
\begin{tabular}{|M{2.0cm}|M{2.0cm}|M{2.0cm}|M{2.0cm}|M{2.0cm}|}
	\hline
	\centering{} & \centering{\textbf{Pos. as Pos.}} & \centering{\textbf{Neg. as Pos.}} & \centering{\textbf{Pos. as Neg.}} & \centering{\textbf{Neg. as Neg.}}\tabularnewline
	\hline
	\centering{\textbf{AdaBoost Classifier}} & \centering{904} & \centering{6} & \centering{3} & \centering{36}\tabularnewline
	\hline
	\centering{\textbf{AdaBoost Regressor}} & \centering{902} & \centering{6} & \centering{5} & \centering{36}\tabularnewline
	\hline
	\centering{\textbf{XGB Classifier}} & \centering{902} & \centering{6} & \centering{5} & \centering{36}\tabularnewline
	\hline
	\centering{\textbf{XGB Regressor}} & \centering{902} & \centering{6} & \centering{5} & \centering{36}\tabularnewline
	\hline
	\centering{\textbf{Random Forest Classifier}} & \centering{902} & \centering{6} & \centering{5} & \centering{36}\tabularnewline
	\hline
	\centering{\textbf{Random Forest Regressor}} & \centering{902} & \centering{6} & \centering{5} & \centering{36}\tabularnewline
	\hline	
\end{tabular}
% Or to place a caption below a table
\caption{Confusion matrices for all algorithms on third group.
Note that 949 samples are shown in the table (10\% of samples that were used for test).}
\end{table}

\subsection{Results of fourth group (9,577 samples; 95.625\% malicious / 4.375\% benign; random pages for text \& image):}
\indent	In this group, as written above, the dataset is much bigger, with mostly benign samples. The difference between this group and the previous one is the way the choice of the page for the image and text is made. Here the choice for these is made randomly.

\noindent\underline{Accuracy Parameters:}

\indent	As can be seen in the accuracy parameters below, the random choice of pages for the image and text extraction has decreased the performance of the fourth machine. The highest accuracy was received from AdaBoost classifier and RF classifier with 98.63\% accuracy. The rest of the algorithms had the same accuracy, 98.52\%, only 0.11\% less than the two leading algorithms.

\clearpage
\newpage

\begin{table}[htb]
\centering
\begin{tabular}{|M{1.2in}|M{0.6in}|M{0.5in}|M{0.6in}|M{0.4in}|M{0.4in}|}\hline
  & \centering{\textbf{Accuracy}} & \centering{\textbf{Class}} & 		\centering{\textbf{Precision}} & \centering{\textbf{Recall}} & \centering{\textbf{F1-Score}}\tabularnewline \cline{1-6}
  \multirow{2}{1.2in}{\textbf{AdaBoost Classifier}}
  &\multirow{2}{*}{\centering{\textbf{98.63\%}}} & \multirow{1}{*}{\centering{Benign}} & \centering{99\%} & \centering{100\%} & \centering{99\%}\tabularnewline \cline{3-6}
  && \multirow{1}{*}{\centering{Malicious}} & \centering{91\%} & \centering{76\%} & \centering{83\%}\tabularnewline \cline{1-6}
  \multirow{2}{1.2in}{\textbf{AdaBoost Regressor}}
  &\multirow{2}{*}{\centering{98.52\%}} & \multirow{1}{*}{\centering{Benign}} & \centering{99\%} & \centering{100\%} & \centering{99\%}\tabularnewline \cline{3-6}
  && \multirow{1}{*}{\centering{Malicious}} & \centering{89\%} & \centering{76\%} & \centering{82\%}\tabularnewline \cline{1-6}
  \multirow{2}{1.2in}{\textbf{XGB Classifier}}
  &\multirow{2}{*}{\centering{98.52\%}} & \multirow{1}{*}{\centering{Benign}} & \centering{99\%} & \centering{100\%} & \centering{99\%}\tabularnewline \cline{3-6}
  && \multirow{1}{*}{\centering{Malicious}} & \centering{89\%} & \centering{76\%} & \centering{82\%}\tabularnewline \cline{1-6}
  \multirow{2}{1.2in}{\textbf{XGB Regressor}}
  &\multirow{2}{*}{\centering{98.52\%}} & \multirow{1}{*}{\centering{Benign}} & \centering{99\%} & \centering{100\%} & \centering{99\%}\tabularnewline \cline{3-6}
  && \multirow{1}{*}{\centering{Malicious}} & \centering{89\%} & \centering{76\%} & \centering{82\%}\tabularnewline \cline{1-6}
  \multirow{2}{1.2in}{\textbf{Random Forest Classifier}}
  &\multirow{2}{*}{\textbf{\centering{98.63\%}}} & \multirow{1}{*}{\centering{Benign}} & \centering{99\%} & \centering{100\%} & \centering{99\%}\tabularnewline \cline{3-6}
  && \multirow{1}{*}{\centering{Malicious}} & \centering{91\%} & \centering{76\%} & \centering{83\%}\tabularnewline \cline{1-6}
  \multirow{2}{1.2in}{\textbf{Random Forest Regressor}}
  &\multirow{2}{*}{\centering{98.52\%}} & \multirow{1}{*}{\centering{Benign}} & \centering{99\%} & \centering{100\%} & \centering{99\%}\tabularnewline \cline{3-6}
  && \multirow{1}{*}{\centering{Malicious}} & \centering{89\%} & \centering{76\%} & \centering{82\%}\tabularnewline \cline{1-6}
\end{tabular}
% Or to place a caption below a table
\caption{Accuracy parameters for all algorithms on fourth group.}
\end{table}

\noindent\underline{Feature Importance:}

\indent	The feature importance has also been affected by the random selection of the pages for the image and text extraction. Most algorithms have increased the importance of the third feature - classification of the PDF features machine.

\begin{table}[htb]
\centering
\begin{tabular}{|M{2.5cm}|M{2.5cm}|M{2.5cm}|M{2.5cm}|}
	\hline
	\centering{} & \centering{\textbf{Image}} & \centering{\textbf{Text}} & \centering{\textbf{Features}}\tabularnewline
	\hline
	\centering{\textbf{AdaBoost Classifier}} & \centering{0.92} & \centering{0.02} & \centering{0.06}\tabularnewline
	\hline
	\centering{\textbf{AdaBoost Regressor}} & \centering{0.16147962} & \centering{0.12584921} & \centering{0.71267117}\tabularnewline
	\hline
	\centering{\textbf{XGB Classifier}} & \centering{0.01837745} & \centering{0.29502392} & \centering{0.71267117}\tabularnewline
	\hline
	\centering{\textbf{XGB Regressor}} & \centering{0.00457967} & \centering{0.29886076} & \centering{0.69655967}\tabularnewline
	\hline
	\centering{\textbf{Random Forest Classifier}} & \centering{0.03530152} & \centering{0.31630768} & \centering{0.6483908}\tabularnewline
	\hline
	\centering{\textbf{Random Forest Regressor}} & \centering{0.01775447} & \centering{0.15577358} & \centering{0.82647196}\tabularnewline
	\hline	
\end{tabular}
% Or to place a caption below a table
\caption{Feature importance for all algorithms on fourth group.}
\end{table}

\noindent\underline{Confusion Matrices}: (Positive = Benign, Negative = Malicious)

\indent Here we present the confusion matrices for all algorithms on the fourth group. As can be seen in the table below, the confusion matrices of all six algorithms are similar.

\begin{table}[htb]
\centering
\begin{tabular}{|M{2.0cm}|M{2.0cm}|M{2.0cm}|M{2.0cm}|M{2.0cm}|}
	\hline
	\centering{} & \centering{\textbf{Pos. as Pos.}} & \centering{\textbf{Neg. as Pos.}} & \centering{\textbf{Pos. as Neg.}} & \centering{\textbf{Neg. as Neg.}}\tabularnewline
	\hline
	\centering{\textbf{AdaBoost Classifier}} & \centering{904} & \centering{10} & \centering{3} & \centering{32}\tabularnewline
	\hline
	\centering{\textbf{AdaBoost Regressor}} & \centering{903} & \centering{10} & \centering{4} & \centering{32}\tabularnewline
	\hline
	\centering{\textbf{XGB Classifier}} & \centering{903} & \centering{10} & \centering{4} & \centering{32}\tabularnewline
	\hline
	\centering{\textbf{XGB Regressor}} & \centering{903} & \centering{10} & \centering{4} & \centering{32}\tabularnewline
	\hline
	\centering{\textbf{Random Forest Classifier}} & \centering{904} & \centering{10} & \centering{3} & \centering{32}\tabularnewline
	\hline
	\centering{\textbf{Random Forest Regressor}} & \centering{903} & \centering{10} & \centering{4} & \centering{32}\tabularnewline
	\hline	
\end{tabular}
% Or to place a caption below a table
\caption{Confusion matrices for all algorithms on fourth group.
Note that 949 samples are shown in the table (10\% of samples that were used for test).}
\end{table}

\subsection{Comparing between results from third and fourth groups:}
\indent In this section we will show the differences between the performances of the models of the third and fourth groups on the second dataset. As can be seen below, there is a slight decrease when the page choice for the extraction of the image and text is done randomly. Each of these groups (third and fourth) has its own advantage. The third group returns slightly better results, but the fourth group handles evasion attacks in the image and text machines. 

\begin{table}[htb]
\centering
\begin{tabular}{|M{1.5cm}|M{1.5cm}|M{1.5cm}|M{1.5cm}|M{1.5cm}|M{1.5cm}|M{1.5cm}|}
	\hline
	\centering{} & \centering{\textbf{AdaBoost Classifier}} & \centering{\textbf{AdaBoost Regressor}} & \centering{\textbf{XGB Classifier}} & \centering{\textbf{XGB Regressor}} & \centering{\textbf{RF Classifier}} & \centering{\textbf{RF Regressor}}\tabularnewline
	\hline
	\centering{\textbf{First Page}} & \centering{\textbf{99.05 \%}} & \centering{98.84 \%} & \centering{98.84 \%} & \centering{98.84 \%} & \centering{98.84 \%} & \centering{98.84 \%}\tabularnewline
	\hline
	\centering{\textbf{Second Page}} & \centering{\textbf{98.63 \%}} & \centering{98.52 \%} & \centering{98.52 \%} & \centering{95.24 \%} & \centering{\textbf{98.63 \%}} & \centering{98.52 \%}\tabularnewline
	\hline
\end{tabular}
% Or to place a caption below a table
\caption{Overall accuracy of the algorithms on the third and fourth group.}
\end{table}

\indent There are plenty of researches that have dealt with evasion attacks in the PDF feature area, therefore we do not focus on this in our work.

\subsection{Comparing our results to results from previous work:}
\indent In our project we have focused on three areas of interest in a PDF file: image, text and PDF features. Most of the previous researches we have read have focused on one main area of interest. These vary from static lexical analysis, JavaScript analysis, PDF features and more. These previous researches have either supplied a tool that identifies malicious files, or a classification model using machine learning. 

\indent In this section we will compare the results we received from our ensemble machine to results from two previous researches. The first research focuses on the PDF feature extraction and machine learning techniques on the vector extracted. This resembles the third machine we have created in our project. The second research focused on the structural properties of PDF files (learning the difference between the structural trees of malicious and benign files). It delves into the relations between the objects of the file in its structural tree. 

\indent In Torres and De Los Santos research that was made in 2018 \cite{torres2018malicious}, they have combined one set of features and three ML algorithms to classify if a PDF is malicious or benign. The features they chose were not presented, but they explained that they were only related to PDF tags (such as /JS,  etc.). The machine learning algorithms they used were SVM, RF, and MLP. Their dataset contained 1,712 samples – half of the samples were malicious and half benign. They divided their dataset in the following way: 995 samples (about 58\%) for training, 217 samples for validation (about 12\%), 500 samples (30\%) for testing. Their results are presented in the table below:

\begin{table}[htb]
\centering
\begin{tabular}{|l|l|}
	\hline
	\centering{\textbf{Algorithm}} & \centering{\textbf{Accuracy}}\tabularnewline
	\hline
	\centering{\textbf{SVM}} & \centering{50\%}\tabularnewline
	\hline
	\centering{\textbf{RF}} & \centering{92\%}\tabularnewline
	\hline
	\centering{\textbf{MLP}} & \centering{96\%}\tabularnewline
	\hline
\end{tabular}
% Or to place a caption below a table
\caption{Overall accuracy of the algorithms.}
\end{table}

\indent As the table above shows, the highest accuracy reached in this research was 96\% with MLP algorithm. We will compare these results with the results presented for the first and second group in the results chapter because of the resemblance between the division of malicious and benign samples in the dataset (made of half malicious and half benign in both). It is important to note that we had less than half the number of samples in the dataset for the first and second group (838 samples) that Torres and De Los Santos had in their research (1,712 samples).

\clearpage
\newpage

\begin{table}[htb]
\centering
\begin{tabular}{|l|M{2.0cm}|M{2.0cm}|M{2.0cm}|M{2.0cm}|}
	\hline
	& \centering{\textbf{SVM - Previous work}} & \centering{\textbf{First Group}} & \centering{\textbf{Second Group}} & \centering{\textbf{Combined Vector} (IMAGE -VECTOR + SVM + 28 features)}\tabularnewline
	\hline
	\centering{\textbf{Accuracy}} & \centering{96\%} & \centering{96.43\%} & \centering{92.86\%} & \centering{98.81\%}\tabularnewline
	\hline
\end{tabular}
% Or to place a caption below a table
\caption{Comparison of overall accuracy between our work and Torres \& De Los Santos’s research.}
\end{table}

\indent In the table above, we compare the results of the first two groups in the results chapter and the best result we have gotten on 838 samples from the fifth phase of our project to the results from the research \cite{torres2018malicious}. In the second group we have worse results, but in the first group and the combined vector, we can see that we reach higher results with less samples. Overall we are pretty close to the results they have gotten from PDF tags feature only.

\indent In another research by researchers from Ben Gurion University \cite{BGU2014malicious} we have seen a different and interesting approach for the identification of malicious PDF files. They implemented the idea presented in Srndic and Laskov \cite{Srndic2013Laskov}. Srndic and Laskov presented a static analysis approach on the hierarchical structural path feature extraction method. This approach makes use of essential differences in the structural properties of malicious and benign PDF files. The structural paths represent the file’s properties and possible actions.

\indent The model presented in \cite{BGU2014malicious} receives new samples every day, part of them were used for retraining the machine, and part used for retesting. The initial dataset contained 76\% benign samples (446 samples) and 24\% malicious (128 samples). Each day they added 160 new samples to the model (adjusting the data to resemble the initial malicious/benign ratio). If an interesting file was located by the model, it was used to retrain the machine. The algorithm they used in their model was SVM-Margin. At the end of 10 days they reached the following results:

\begin{table}[htb]
\centering
\begin{tabular}{|l|l|l|}
	\hline
	& \centering{\textbf{TPR}} & \centering{\textbf{FPR}}\tabularnewline
	\hline
	\centering{\textbf{Third Group (benign = pos.)}} & \centering{99.67\%} & \centering{7.14\%}\tabularnewline
	\hline
	\centering{\textbf{Fourth Group (benign = pos.)}} & \centering{99.67\%} & \centering{7.14\%}\tabularnewline
	\hline
	\centering{\textbf{Third Group (malicious = pos.)}} & \centering{85.71\%} & \centering{0.66\%}\tabularnewline
	\hline
	\centering{\textbf{Fourth Group (malicious = pos.)}} & \centering{76.19\%} & \centering{1.10\%}\tabularnewline
	\hline
	\centering{\textbf{SVM-Margin (10 day)}} & \centering{96\%} & \centering{0.05\%}\tabularnewline
	\hline
\end{tabular}
% Or to place a caption below a table
\caption{Comparison of overall TPR and FPR between our work and researchers from Ben Gurion University.}
\end{table}

\indent In the results of \cite{BGU2014malicious}, they have not shown accuracy, only the TPR (true positive rate) and FPR (false positive rate) measurements of their work. In their work they have related to malicious samples as positive. In the table above these measurements are compared to ours. As can be seen, their research has returned better results. By the measurements above we can see that our model is very good for the identification of benign PDF files, but not as much for malicious PDF files. The fact that there were very few malicious samples in our dataset (4.375\% malicious samples in our dataset compared to 24\% malicious samples in their dataset) made the machines look for very specific things about the malicious files, therefore reaching not good enough results for our model.

\indent In order to compare the models in a better way (to both researches), we need to increase the number of malicious samples in our datasets, and adjust the datasets in a way that will match the datasets in the two researches shown above in a better way (size and content of our dataset).

\subsection{Conclusion}
\indent The aim of our project was to create an ensemble machine that will serve as a classifier for PDF files. This ensemble machine focuses on three different areas of the PDF file: image, text and file features. The first machine uses a clustering algorithm on a vector of the image histogram and blur, extracted from the first page of the file. The second machine uses ‘TFIDF’ as the word embedding and logistic regression as the machine learning algorithm to classify the file by the text extracted from the first page of the file. The third machine uses a vector of features extracted from the whole file, and random forest as the machine learning algorithm to classify the file by its features.

\indent During the different phases of our work, while working on each machine, we had tried different approaches for the way of building the vectors, and different deep learning and machine learning algorithms. In addition to that, during our work we met with our advisors and another researcher and talked about different ways that an attacker can evade our ensemble machine. We built an algorithm that instead of always choosing the first page for our two first machines, chooses a random pages of the file for that. 

\indent We have compared our results to two researches that have two different approaches, each focusing on one area of interest of the PDF file. We have indicated what has to be improved in our project and dataset in order to reach more realistic results. The improvements include adding malicious samples to our dataset, and creating a recommended proportion between the malicious and benign files in the dataset as can be seen in \cite{BGU2014malicious}.

\section{Future Work}
\indent During the research and execution of our work, we have encountered many approaches, methods and tools that deal with the identification of malicious PDF files. There are many researches that have developed new approaches and tools with good results. When we started our project, we have focused on three specific areas of interest and machine learning techniques for those three areas. Combining three approaches in one work is relatively not as common, but there are many more methods that can be used and combined in our work. 

\noindent Overall the biggest issues in our work that we would like to address in the future are:
\begin{enumerate}
	\item\underline{The dataset} – We would like to increase the number of malicious samples in the dataset and find the best balance between malicious and benign samples in the dataset \cite{BGU2014malicious}, relevant for all the machines in the project.
	\item\underline{Integration of more methods} – Another option is increasing the number of methods used to classify the files. That means adding machines with more types of classification and increasing the size of the ensemble machine's vector. By methods we mean the feature selection methods (more types of data regarding the file such as object structure, etc.), and the detection approaches (using not only machine learning as has been done, but adding more approaches such as statistical analysis and clustering) \cite{BGU2014survey} \cite{Baldoni2018survey}.
	\item\underline{Training method} – In our work we have trained the machines once, and tested them directly. Another approach that can be implemented is using a retraining method, that trains the machines periodically or every time there is more samples, this way maybe we can achieve better results.
\end{enumerate}

\noindent With all that said, each phase of our project can be improved itself, we present these improvements in the sections below.

\subsection{Phase 2 Improvements}
\subsubsection{Additional methods of picture classification}
\indent Histogram is clearly not the only approach existing in the classification of images. Comparing the vector that we created with other approaches may yield better results than the results we achieved.

\subsubsection{Near Similar Image Matching}
\indent Image matching may be another way to reach image classification in PDF files. It works by detecting special features of the image and comparing to others.

\subsection{Phase 3 Improvements }
\subsubsection{Extraction of text to work for more languages}
\indent In our project the extraction of text from image works only for Latin and Cyrillic characters. That means that if there is another language and we have to extract the text from the image, the text machine won't work. Furthermore, if the text is directly extracted from the file or from the image of the file, and is not in English, it will be needed to write a machine suitable for that language (the machine we built works only on English text).

\subsubsection{Improving text vector}
\indent During our work we considered trying another approach of creating the text vector using ‘Word2vec’ with cosine similarity. Due to time limitations we did not get to do it.

\indent Moreover, we used a slim dictionary due to memory limitations, but there are many advanced dictionaries that also include relations between words and phrases that can be used and may improve results.

\subsection{Phase 4 Improvements} 
\subsubsection{Feature selection improvement}
\indent During our work, we have read many articles and researches that focus on whole file features, PDF tags, and more. Many of these did not mention specifically what they used, and many did. We could not include everything in our work, but we could try to make a few combinations to see if we can reach better results just by changing the features in our vector. 

\indent An example for features we did not know about was ‘SubmitForm’, a PDF tag we discovered while writing the project book \cite{Hamon2013malicious}. Another example is “/GoTo” \cite{BGU2014malicious}.

\indent Another approach of improving the vector is combining features, for example instead of creating a feature for the /Obj tag and another for /EndObj tag, creating one feature that indicates if the number of objects opened and the number of the objects closed are the same or not.

\indent Another idea is adding the approach that uses N-Grams in order to distinguish between benign and malicious PDF files. This can be seen in \cite{Joachims1999Thorsten}.

\indent Lastly, we could create a list of all possible features, and choose randomly from it repeatedly until we find the list that yields us the best classification.

\subsection{Phase 5 Improvements}
\subsubsection{Additional methods}
\indent In the ensemble machine we could continue trying to improve the vector and the algorithms used in order to reach better results.

\subsection{Missing trailer \& malformation in ‘xref’ table}
\indent We have encountered numerous problems with files that did not have trailers. Even though in Didier Stevens’s work \cite{1} it is mentioned that this does not necessarily affect the files, it caused us not to be able to open them.

\indent Moreover, we did not delve into the area of malformations in the PDF file. Throughout our work we have seen researches that focused specifically in this area \cite{torres2018malicious} \cite{OtsuboChecker}, and learnt for example that if there are objects in the file that do not appear in the ‘xref’ table, there is a high chance that a benign file was altered to contain malicious contents.


%-------------------------------------------------------REFERENCES----------------------------------------------
\medskip
 
\begin{thebibliography}{9}
\bibitem{patil2018malicious} 
Patil, Dharmaraj R and Patil, JB. 
\textit{Cybernetics and Information Technologies}.
[\textit{Malicious URLs Detection Using Decision Tree Classifiers and Majority Voting Technique}]. 
pages:11–29, 2018.

\bibitem{torres2018malicious} 
Torres, Jose and De Los Santos, Sergio. 
\textit{Malicious PDF Documents Detection using Machine Learning Techniques}. 
2018.
  
\bibitem{1} 
Didier Stevens.
\textit{Pdf Tools}. 
\texttt{https://blog.didierstevens.com/programs/pdf-tools/}
2017.

\bibitem{davide2019malicious} 
Davide Maiorca, Battista Biggio and Giorgio Giacinto. 
\textit{Towards Adversarial Malware Detection: Lessons Learned from PDF-based Attacks}. 
April 2019.

\bibitem{BGU2014malicious} 
Nir Nissim, Aviad Cohen, Robert Moskovitch, Asaf Shabtai, Matan Edri, Oren BarAd and Yuval Elovici. 
\textit{Keeping pace with the creation of new malicious PDF files using an active-learning based detection framework}. 

\bibitem{BGU2014survey} 
Nir Nissim, Aviad Cohen, Chanan Glezer and Yuval Elovici. 
\textit{Detection of Malicious PDF files and directions for enhancements: A state-of-the-art survey}.                                             

\bibitem{JSSrndic2011Laskov}
Nedim Srndic and Pavel Laskov.
\textit{Static Detection of Malicious JavaScript-Bearing PDF Documents}.
2011.

\bibitem{Srndic2013Laskov} 
Nedim Srndic and Pavel Laskov. 
\textit{Detection of Malicious PDF Files Based on Hierarchical Document Structure}.                                             
2013.

\bibitem{Baldoni2018survey} 
Michele Elingiusti, Leonardo Aniello, Leonardo Querzoni and Roberto Baldoni. 
\textit{PDF-Malware Detection: A Survey and Taxonomy of Current Techniques}.                                             
2018. 

\bibitem{Hamon2013malicious} 
Hamon Valentin. 
\textit{Malicious URI Resolving in PDF Documents}.                                             
2013.

\bibitem{Joachims1999Thorsten} 
Joachims Thorsten.
\textit{Making Large Scale SVM Learning Practical}.                                             
1999.

\bibitem{OtsuboChecker} 
Yuhei Otsubo.
\textit{O-checker: Detection of Malicious Documents through Deviation from File Format Specification}. 

\bibitem{Bonan2018ML}
Bonan Cuan, Aliénor Damien, Claire Delaplace, Mathieu Valois.
\textit{Malware Detection in PDF Files Using Machine Learning}.
2018.

\bibitem{JAST2018}
Aurore Fass, Robert P. Krawczyk, Michael Backes, Ben Stock.
\textit{JaSt: Fully Syntactic Detection of Malicious (Obfuscated) JavaScript}.
2018.

\bibitem{AnalyzePDF2014} 
Hiddenillusion.
\textit{AnalyzePDF}. 
\texttt{https://github.com/hiddenillusion/AnalyzePDF}
2014.

\bibitem{Peepdf2016} 
Jesparza.
\textit{PeePDF}. 
\texttt{https://github.com/jesparza/peepdf}
2016.

\bibitem{HistogramImage} 
Adrian Rosebrock.
\textit{KNN Classifier for Image Classification}. 
\texttt{https://www.pyimagesearch.com/2016/08/08/k-nn-classifier-for-image-classification/}
2016.

\end{thebibliography}

\end{document}
